WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
loss DRSL3 b=1e-05 start=0 end=20loss DRSL3 b=1e-05 start=0 end=20

loss DRSL3 b=1e-05 start=0 end=20
loss DRSL3 b=1e-05 start=0 end=20
| distributed init (rank 3, world 4): env://
| distributed init (rank 2, world 4): env://| distributed init (rank 1, world 4): env://| distributed init (rank 0, world 4): env://


[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
2023-08-19 14:44:31,222 [INFO] 
=====  Running Parameters    =====
2023-08-19 14:44:31,222 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 2,
    "batch_size_train": 12,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1,
    "max_len": 30,
    "min_len": 8,
    "min_lr": 0,
    "num_beams": 5,
    "num_workers": 4,
    "output_dir": "output3/BLIP2/Caption_coco_drsl_0_20",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "captioning",
    "train_splits": [
        "train"
    ],
    "warmup_lr": 1e-08,
    "warmup_steps": 1000,
    "weight_decay": 0.05,
    "world_size": 4
}
2023-08-19 14:44:31,223 [INFO] 
======  Dataset Attributes  ======
2023-08-19 14:44:31,223 [INFO] 
======== coco_caption =======
2023-08-19 14:44:31,224 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a photo of "
        }
    },
    "vis_processor": {
        "eval": {
            "image_size": 364,
            "name": "blip_image_eval"
        },
        "train": {
            "image_size": 364,
            "name": "blip2_image_train"
        }
    }
}
2023-08-19 14:44:31,224 [INFO] 
======  Model Attributes  ======
2023-08-19 14:44:31,224 [INFO] {
    "arch": "blip2_opt",
    "drop_path_rate": 0,
    "freeze_vit": true,
    "image_size": 364,
    "load_finetuned": false,
    "model_type": "caption_coco_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth",
    "prompt": "a photo of",
    "use_grad_checkpoint": true,
    "vit_precision": "fp32"
}
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-08-19 14:44:31,239 [INFO] Building datasets...
BlipImageEvalProcessor
Position interpolate from 16x16 to 26x26
2023-08-19 14:45:10,243 [INFO] freeze vision encoder
https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth
2023-08-19 14:48:33,839 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth
2023-08-19 14:48:33,872 [INFO] Start training
2023-08-19 14:48:54,931 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-08-19 14:48:54,932 [INFO] Loaded 566747 records for train split from the dataset.
2023-08-19 14:48:54,932 [INFO] Loaded 5000 records for val split from the dataset.
2023-08-19 14:48:54,933 [INFO] Loaded 5000 records for test split from the dataset.
2023-08-19 14:48:54,985 [INFO] number of trainable parameters: 107133696
2023-08-19 14:48:54,986 [INFO] Start training epoch 0, 11807 iters per inner epoch.
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Train: data epoch: [0]  [    0/11807]  eta: 3 days, 11:24:30  lr: 0.000000  loss: 2.0367  time: 25.4316  data: 0.0000  max mem: 13105
2023-08-19 14:49:20,464 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [   50/11807]  eta: 18:54:23  lr: 0.000001  loss: 2.3927  time: 5.4403  data: 0.0000  max mem: 14867
Train: data epoch: [0]  [  100/11807]  eta: 18:20:19  lr: 0.000001  loss: 2.1089  time: 5.4810  data: 0.0000  max mem: 14867
Train: data epoch: [0]  [  150/11807]  eta: 18:05:25  lr: 0.000002  loss: 1.6541  time: 5.4816  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  200/11807]  eta: 17:57:52  lr: 0.000002  loss: 1.6331  time: 5.5976  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  250/11807]  eta: 17:50:14  lr: 0.000003  loss: 2.0303  time: 5.4745  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  300/11807]  eta: 17:43:28  lr: 0.000003  loss: 1.8268  time: 5.5040  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  350/11807]  eta: 17:37:25  lr: 0.000004  loss: 1.9645  time: 5.4828  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  400/11807]  eta: 17:31:37  lr: 0.000004  loss: 1.7779  time: 5.4708  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  450/11807]  eta: 17:26:18  lr: 0.000005  loss: 2.2172  time: 5.5385  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  500/11807]  eta: 17:21:07  lr: 0.000005  loss: 2.0274  time: 5.5194  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  550/11807]  eta: 17:15:48  lr: 0.000006  loss: 2.1155  time: 5.4610  data: 0.0000  max mem: 14891
Train: data epoch: [0]  [  600/11807]  eta: 17:11:07  lr: 0.000006  loss: 2.0438  time: 5.4761  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [  650/11807]  eta: 17:06:04  lr: 0.000007  loss: 2.0833  time: 5.4900  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [  700/11807]  eta: 17:01:05  lr: 0.000007  loss: 1.7002  time: 5.5026  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [  750/11807]  eta: 16:56:13  lr: 0.000008  loss: 1.7078  time: 5.5036  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [  800/11807]  eta: 16:51:06  lr: 0.000008  loss: 1.8101  time: 5.4421  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [  850/11807]  eta: 16:46:29  lr: 0.000009  loss: 2.1479  time: 5.4842  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [  900/11807]  eta: 16:41:39  lr: 0.000009  loss: 2.2576  time: 5.5060  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [  950/11807]  eta: 16:36:38  lr: 0.000010  loss: 2.0197  time: 5.4605  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1000/11807]  eta: 16:31:58  lr: 0.000010  loss: 2.3918  time: 5.5283  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1050/11807]  eta: 16:27:15  lr: 0.000010  loss: 2.0666  time: 5.4959  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1100/11807]  eta: 16:22:35  lr: 0.000010  loss: 1.9389  time: 5.4903  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1150/11807]  eta: 16:17:52  lr: 0.000010  loss: 2.0761  time: 5.5023  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1200/11807]  eta: 16:13:14  lr: 0.000010  loss: 2.0012  time: 5.5212  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1250/11807]  eta: 16:08:31  lr: 0.000010  loss: 1.6639  time: 5.4552  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1300/11807]  eta: 16:03:48  lr: 0.000010  loss: 2.3985  time: 5.4671  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1350/11807]  eta: 15:59:11  lr: 0.000010  loss: 1.6870  time: 5.5327  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1400/11807]  eta: 15:54:40  lr: 0.000010  loss: 2.0527  time: 5.5094  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1450/11807]  eta: 15:50:04  lr: 0.000010  loss: 1.8579  time: 5.5238  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1500/11807]  eta: 15:45:26  lr: 0.000010  loss: 1.9554  time: 5.5031  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1550/11807]  eta: 15:40:55  lr: 0.000010  loss: 2.0718  time: 5.4600  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1600/11807]  eta: 15:36:15  lr: 0.000010  loss: 2.6672  time: 5.4879  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1650/11807]  eta: 15:31:32  lr: 0.000010  loss: 2.1833  time: 5.5018  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1700/11807]  eta: 15:26:57  lr: 0.000010  loss: 2.4152  time: 5.4966  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1750/11807]  eta: 15:22:12  lr: 0.000010  loss: 2.1693  time: 5.4935  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1800/11807]  eta: 15:17:34  lr: 0.000010  loss: 2.3894  time: 5.4891  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1850/11807]  eta: 15:13:02  lr: 0.000010  loss: 1.8597  time: 5.4889  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1900/11807]  eta: 15:08:31  lr: 0.000010  loss: 1.8599  time: 5.4926  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 1950/11807]  eta: 15:03:55  lr: 0.000010  loss: 2.1913  time: 5.4619  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2000/11807]  eta: 14:59:21  lr: 0.000010  loss: 1.8813  time: 5.5048  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2050/11807]  eta: 14:54:37  lr: 0.000010  loss: 2.0250  time: 5.4227  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2100/11807]  eta: 14:49:55  lr: 0.000010  loss: 2.0136  time: 5.4838  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2150/11807]  eta: 14:45:16  lr: 0.000010  loss: 2.1673  time: 5.4707  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2200/11807]  eta: 14:40:38  lr: 0.000010  loss: 2.0465  time: 5.4884  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2250/11807]  eta: 14:36:06  lr: 0.000010  loss: 1.7987  time: 5.4912  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2300/11807]  eta: 14:31:35  lr: 0.000010  loss: 2.3615  time: 5.5097  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2350/11807]  eta: 14:26:56  lr: 0.000010  loss: 2.0941  time: 5.4872  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2400/11807]  eta: 14:22:22  lr: 0.000010  loss: 2.0944  time: 5.4840  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2450/11807]  eta: 14:17:47  lr: 0.000010  loss: 1.7972  time: 5.5256  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2500/11807]  eta: 14:13:13  lr: 0.000010  loss: 2.0136  time: 5.5144  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2550/11807]  eta: 14:08:34  lr: 0.000010  loss: 1.9884  time: 5.4956  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2600/11807]  eta: 14:03:54  lr: 0.000010  loss: 2.0657  time: 5.4945  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2650/11807]  eta: 13:59:13  lr: 0.000010  loss: 1.7695  time: 5.4482  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2700/11807]  eta: 13:54:38  lr: 0.000010  loss: 2.5057  time: 5.5064  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2750/11807]  eta: 13:50:07  lr: 0.000010  loss: 1.9127  time: 5.5487  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2800/11807]  eta: 13:45:27  lr: 0.000010  loss: 1.9700  time: 5.5095  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2850/11807]  eta: 13:40:50  lr: 0.000010  loss: 2.0085  time: 5.4794  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2900/11807]  eta: 13:36:12  lr: 0.000010  loss: 1.7478  time: 5.4594  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 2950/11807]  eta: 13:31:37  lr: 0.000010  loss: 2.0695  time: 5.4849  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3000/11807]  eta: 13:27:05  lr: 0.000010  loss: 1.7479  time: 5.5400  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3050/11807]  eta: 13:22:27  lr: 0.000010  loss: 2.0818  time: 5.4259  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3100/11807]  eta: 13:17:55  lr: 0.000010  loss: 2.2931  time: 5.5060  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3150/11807]  eta: 13:13:17  lr: 0.000010  loss: 1.9221  time: 5.4791  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3200/11807]  eta: 13:08:40  lr: 0.000010  loss: 2.2931  time: 5.4598  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3250/11807]  eta: 13:04:09  lr: 0.000010  loss: 2.4476  time: 5.5362  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3300/11807]  eta: 12:59:33  lr: 0.000010  loss: 2.0793  time: 5.4895  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3350/11807]  eta: 12:55:02  lr: 0.000010  loss: 1.9785  time: 5.5245  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3400/11807]  eta: 12:50:28  lr: 0.000010  loss: 2.4689  time: 5.4798  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3450/11807]  eta: 12:45:45  lr: 0.000010  loss: 2.2337  time: 5.4628  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3500/11807]  eta: 12:41:07  lr: 0.000010  loss: 2.1183  time: 5.4778  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3550/11807]  eta: 12:36:31  lr: 0.000010  loss: 2.1020  time: 5.4816  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3600/11807]  eta: 12:31:55  lr: 0.000010  loss: 2.0766  time: 5.4822  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3650/11807]  eta: 12:27:19  lr: 0.000010  loss: 1.9066  time: 5.5167  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3700/11807]  eta: 12:22:43  lr: 0.000010  loss: 1.9294  time: 5.4748  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3750/11807]  eta: 12:18:09  lr: 0.000010  loss: 2.5409  time: 5.4704  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3800/11807]  eta: 12:13:34  lr: 0.000010  loss: 1.8395  time: 5.5378  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3850/11807]  eta: 12:08:55  lr: 0.000010  loss: 2.1028  time: 5.4719  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3900/11807]  eta: 12:04:19  lr: 0.000010  loss: 1.7412  time: 5.4776  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 3950/11807]  eta: 11:59:45  lr: 0.000010  loss: 2.0310  time: 5.4918  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4000/11807]  eta: 11:55:10  lr: 0.000010  loss: 2.1004  time: 5.4779  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4050/11807]  eta: 11:50:37  lr: 0.000010  loss: 2.1485  time: 5.4637  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4100/11807]  eta: 11:46:02  lr: 0.000010  loss: 1.8956  time: 5.4789  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4150/11807]  eta: 11:41:28  lr: 0.000010  loss: 2.2042  time: 5.5550  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4200/11807]  eta: 11:36:54  lr: 0.000010  loss: 2.0255  time: 5.5210  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4250/11807]  eta: 11:32:17  lr: 0.000010  loss: 2.0007  time: 5.4866  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4300/11807]  eta: 11:27:42  lr: 0.000010  loss: 2.3947  time: 5.4539  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4350/11807]  eta: 11:23:08  lr: 0.000010  loss: 2.2552  time: 5.4770  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4400/11807]  eta: 11:18:34  lr: 0.000010  loss: 2.2261  time: 5.4935  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4450/11807]  eta: 11:13:59  lr: 0.000010  loss: 2.0345  time: 5.5321  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4500/11807]  eta: 11:09:26  lr: 0.000010  loss: 2.0511  time: 5.5182  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4550/11807]  eta: 11:04:52  lr: 0.000010  loss: 2.2779  time: 5.5244  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4600/11807]  eta: 11:00:16  lr: 0.000010  loss: 2.3269  time: 5.4810  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4650/11807]  eta: 10:55:40  lr: 0.000010  loss: 2.0497  time: 5.4742  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4700/11807]  eta: 10:51:05  lr: 0.000010  loss: 2.1802  time: 5.4751  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4750/11807]  eta: 10:46:28  lr: 0.000010  loss: 2.3231  time: 5.4793  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4800/11807]  eta: 10:41:51  lr: 0.000010  loss: 2.1611  time: 5.4205  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4850/11807]  eta: 10:37:15  lr: 0.000010  loss: 1.8842  time: 5.4503  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4900/11807]  eta: 10:32:39  lr: 0.000010  loss: 2.2765  time: 5.4478  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 4950/11807]  eta: 10:28:03  lr: 0.000010  loss: 2.1099  time: 5.4673  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5000/11807]  eta: 10:23:28  lr: 0.000010  loss: 2.3572  time: 5.4809  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5050/11807]  eta: 10:18:52  lr: 0.000010  loss: 1.7748  time: 5.4807  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5100/11807]  eta: 10:14:15  lr: 0.000010  loss: 2.2909  time: 5.4848  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5150/11807]  eta: 10:09:40  lr: 0.000010  loss: 1.9321  time: 5.5010  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5200/11807]  eta: 10:05:06  lr: 0.000010  loss: 1.7750  time: 5.5471  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5250/11807]  eta: 10:00:30  lr: 0.000010  loss: 1.9570  time: 5.4649  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5300/11807]  eta: 9:55:57  lr: 0.000010  loss: 2.4831  time: 5.4867  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5350/11807]  eta: 9:51:22  lr: 0.000010  loss: 1.8810  time: 5.4411  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5400/11807]  eta: 9:46:47  lr: 0.000010  loss: 2.4306  time: 5.4617  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5450/11807]  eta: 9:42:12  lr: 0.000010  loss: 2.3227  time: 5.4819  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5500/11807]  eta: 9:37:38  lr: 0.000010  loss: 2.1453  time: 5.5608  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5550/11807]  eta: 9:33:02  lr: 0.000010  loss: 2.5624  time: 5.4666  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5600/11807]  eta: 9:28:27  lr: 0.000010  loss: 1.9361  time: 5.5278  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5650/11807]  eta: 9:23:52  lr: 0.000010  loss: 1.7102  time: 5.4913  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5700/11807]  eta: 9:19:17  lr: 0.000010  loss: 2.1712  time: 5.5082  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5750/11807]  eta: 9:14:43  lr: 0.000010  loss: 2.2288  time: 5.4783  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5800/11807]  eta: 9:10:10  lr: 0.000010  loss: 2.0867  time: 5.5575  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5850/11807]  eta: 9:05:33  lr: 0.000010  loss: 1.9495  time: 5.4399  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5900/11807]  eta: 9:00:58  lr: 0.000010  loss: 2.3874  time: 5.4904  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 5950/11807]  eta: 8:56:25  lr: 0.000010  loss: 2.0749  time: 5.4931  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 6000/11807]  eta: 8:51:50  lr: 0.000010  loss: 2.5206  time: 5.5258  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 6050/11807]  eta: 8:47:15  lr: 0.000010  loss: 2.3710  time: 5.4809  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 6100/11807]  eta: 8:42:41  lr: 0.000010  loss: 2.3965  time: 5.4923  data: 0.0000  max mem: 14905
Train: data epoch: [0]  [ 6150/11807]  eta: 8:38:07  lr: 0.000010  loss: 2.0965  time: 5.5133  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6200/11807]  eta: 8:33:32  lr: 0.000010  loss: 1.9458  time: 5.5138  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6250/11807]  eta: 8:28:57  lr: 0.000010  loss: 1.7882  time: 5.5162  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6300/11807]  eta: 8:24:22  lr: 0.000010  loss: 1.5995  time: 5.4906  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6350/11807]  eta: 8:19:47  lr: 0.000010  loss: 2.1746  time: 5.5192  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6400/11807]  eta: 8:15:13  lr: 0.000010  loss: 2.3911  time: 5.4906  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6450/11807]  eta: 8:10:37  lr: 0.000010  loss: 2.2465  time: 5.5079  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6500/11807]  eta: 8:06:03  lr: 0.000010  loss: 2.0020  time: 5.5544  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6550/11807]  eta: 8:01:27  lr: 0.000010  loss: 1.7793  time: 5.5099  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6600/11807]  eta: 7:56:51  lr: 0.000010  loss: 1.6291  time: 5.4684  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6650/11807]  eta: 7:52:15  lr: 0.000010  loss: 2.0407  time: 5.4490  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6700/11807]  eta: 7:47:39  lr: 0.000010  loss: 2.3125  time: 5.4755  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6750/11807]  eta: 7:43:05  lr: 0.000010  loss: 2.0036  time: 5.5259  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6800/11807]  eta: 7:38:30  lr: 0.000010  loss: 2.0827  time: 5.4847  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6850/11807]  eta: 7:33:55  lr: 0.000010  loss: 2.2911  time: 5.4566  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6900/11807]  eta: 7:29:19  lr: 0.000010  loss: 1.9527  time: 5.4557  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 6950/11807]  eta: 7:24:44  lr: 0.000010  loss: 1.9350  time: 5.4690  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7000/11807]  eta: 7:20:09  lr: 0.000010  loss: 1.9173  time: 5.4889  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7050/11807]  eta: 7:15:34  lr: 0.000010  loss: 1.8508  time: 5.4864  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7100/11807]  eta: 7:10:59  lr: 0.000010  loss: 1.8316  time: 5.4985  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7150/11807]  eta: 7:06:24  lr: 0.000010  loss: 2.2004  time: 5.4732  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7200/11807]  eta: 7:01:49  lr: 0.000010  loss: 1.7276  time: 5.4588  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7250/11807]  eta: 6:57:14  lr: 0.000010  loss: 1.9323  time: 5.4682  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7300/11807]  eta: 6:52:39  lr: 0.000010  loss: 2.0205  time: 5.5100  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7350/11807]  eta: 6:48:04  lr: 0.000010  loss: 1.8299  time: 5.4820  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7400/11807]  eta: 6:43:30  lr: 0.000010  loss: 1.8741  time: 5.5260  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7450/11807]  eta: 6:38:55  lr: 0.000010  loss: 2.1017  time: 5.4996  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7500/11807]  eta: 6:34:20  lr: 0.000010  loss: 2.1483  time: 5.4525  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7550/11807]  eta: 6:29:45  lr: 0.000010  loss: 1.9861  time: 5.4723  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7600/11807]  eta: 6:25:09  lr: 0.000010  loss: 2.3942  time: 5.4724  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7650/11807]  eta: 6:20:35  lr: 0.000010  loss: 2.3079  time: 5.4965  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7700/11807]  eta: 6:16:00  lr: 0.000010  loss: 1.7635  time: 5.4583  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7750/11807]  eta: 6:11:26  lr: 0.000010  loss: 2.3186  time: 5.5119  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7800/11807]  eta: 6:06:51  lr: 0.000010  loss: 2.1250  time: 5.4736  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7850/11807]  eta: 6:02:17  lr: 0.000010  loss: 1.8621  time: 5.5123  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7900/11807]  eta: 5:57:42  lr: 0.000010  loss: 2.4235  time: 5.5038  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 7950/11807]  eta: 5:53:08  lr: 0.000010  loss: 2.4105  time: 5.5133  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8000/11807]  eta: 5:48:34  lr: 0.000010  loss: 2.2530  time: 5.4963  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8050/11807]  eta: 5:43:59  lr: 0.000010  loss: 2.4678  time: 5.5173  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8100/11807]  eta: 5:39:25  lr: 0.000010  loss: 1.6857  time: 5.4913  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8150/11807]  eta: 5:34:50  lr: 0.000010  loss: 2.4050  time: 5.4567  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8200/11807]  eta: 5:30:16  lr: 0.000010  loss: 2.3286  time: 5.5232  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8250/11807]  eta: 5:25:41  lr: 0.000010  loss: 2.3099  time: 5.4817  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8300/11807]  eta: 5:21:06  lr: 0.000010  loss: 2.0204  time: 5.4775  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8350/11807]  eta: 5:16:31  lr: 0.000010  loss: 2.1996  time: 5.4690  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8400/11807]  eta: 5:11:57  lr: 0.000010  loss: 2.0667  time: 5.5103  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8450/11807]  eta: 5:07:22  lr: 0.000010  loss: 2.4895  time: 5.5462  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8500/11807]  eta: 5:02:47  lr: 0.000010  loss: 1.8250  time: 5.4734  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8550/11807]  eta: 4:58:12  lr: 0.000010  loss: 2.3973  time: 5.4858  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8600/11807]  eta: 4:53:38  lr: 0.000010  loss: 2.1156  time: 5.5067  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8650/11807]  eta: 4:49:03  lr: 0.000010  loss: 2.3557  time: 5.4919  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8700/11807]  eta: 4:44:29  lr: 0.000010  loss: 2.3120  time: 5.4813  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8750/11807]  eta: 4:39:54  lr: 0.000010  loss: 2.1797  time: 5.5213  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8800/11807]  eta: 4:35:20  lr: 0.000010  loss: 2.1015  time: 5.5344  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8850/11807]  eta: 4:30:45  lr: 0.000010  loss: 1.7005  time: 5.5090  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8900/11807]  eta: 4:26:10  lr: 0.000010  loss: 1.8652  time: 5.4516  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 8950/11807]  eta: 4:21:36  lr: 0.000010  loss: 2.0318  time: 5.5335  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9000/11807]  eta: 4:17:01  lr: 0.000010  loss: 2.3799  time: 5.4486  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9050/11807]  eta: 4:12:26  lr: 0.000010  loss: 2.1871  time: 5.5005  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9100/11807]  eta: 4:07:51  lr: 0.000010  loss: 2.0944  time: 5.5128  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9150/11807]  eta: 4:03:17  lr: 0.000010  loss: 2.0205  time: 5.5128  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9200/11807]  eta: 3:58:42  lr: 0.000010  loss: 1.6898  time: 5.4764  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9250/11807]  eta: 3:54:07  lr: 0.000010  loss: 2.2706  time: 5.4966  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9300/11807]  eta: 3:49:32  lr: 0.000010  loss: 1.9061  time: 5.4313  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9350/11807]  eta: 3:44:57  lr: 0.000010  loss: 2.0699  time: 5.5173  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9400/11807]  eta: 3:40:22  lr: 0.000010  loss: 2.0991  time: 5.4994  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9450/11807]  eta: 3:35:48  lr: 0.000010  loss: 2.0059  time: 5.4946  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9500/11807]  eta: 3:31:13  lr: 0.000010  loss: 2.4322  time: 5.5386  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9550/11807]  eta: 3:26:38  lr: 0.000010  loss: 2.1024  time: 5.4617  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9600/11807]  eta: 3:22:03  lr: 0.000010  loss: 1.8687  time: 5.4423  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9650/11807]  eta: 3:17:29  lr: 0.000010  loss: 1.8371  time: 5.5079  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9700/11807]  eta: 3:12:54  lr: 0.000010  loss: 1.7999  time: 5.5763  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9750/11807]  eta: 3:08:20  lr: 0.000010  loss: 2.4819  time: 5.4591  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9800/11807]  eta: 3:03:45  lr: 0.000010  loss: 2.2593  time: 5.4864  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9850/11807]  eta: 2:59:10  lr: 0.000010  loss: 2.2932  time: 5.4643  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9900/11807]  eta: 2:54:36  lr: 0.000010  loss: 2.1008  time: 5.4999  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [ 9950/11807]  eta: 2:50:01  lr: 0.000010  loss: 1.9751  time: 5.4952  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10000/11807]  eta: 2:45:26  lr: 0.000010  loss: 2.2416  time: 5.4647  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10050/11807]  eta: 2:40:52  lr: 0.000010  loss: 1.9318  time: 5.5198  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10100/11807]  eta: 2:36:17  lr: 0.000010  loss: 2.0464  time: 5.5101  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10150/11807]  eta: 2:31:42  lr: 0.000010  loss: 2.2237  time: 5.4874  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10200/11807]  eta: 2:27:07  lr: 0.000010  loss: 1.7644  time: 5.4779  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10250/11807]  eta: 2:22:33  lr: 0.000010  loss: 2.1558  time: 5.5534  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10300/11807]  eta: 2:17:58  lr: 0.000010  loss: 2.3136  time: 5.4986  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10350/11807]  eta: 2:13:23  lr: 0.000010  loss: 2.1162  time: 5.4850  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10400/11807]  eta: 2:08:49  lr: 0.000010  loss: 2.2704  time: 5.4589  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10450/11807]  eta: 2:04:14  lr: 0.000010  loss: 1.8248  time: 5.5178  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10500/11807]  eta: 1:59:39  lr: 0.000010  loss: 1.8917  time: 5.4761  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10550/11807]  eta: 1:55:05  lr: 0.000010  loss: 2.4967  time: 5.5025  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10600/11807]  eta: 1:50:30  lr: 0.000010  loss: 2.3014  time: 5.5260  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10650/11807]  eta: 1:45:55  lr: 0.000010  loss: 2.0903  time: 5.5247  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10700/11807]  eta: 1:41:21  lr: 0.000010  loss: 2.2295  time: 5.4638  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10750/11807]  eta: 1:36:46  lr: 0.000010  loss: 1.9242  time: 5.4436  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10800/11807]  eta: 1:32:11  lr: 0.000010  loss: 2.0963  time: 5.5200  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10850/11807]  eta: 1:27:37  lr: 0.000010  loss: 2.3749  time: 5.4899  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10900/11807]  eta: 1:23:02  lr: 0.000010  loss: 2.2425  time: 5.5158  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [10950/11807]  eta: 1:18:27  lr: 0.000010  loss: 1.8912  time: 5.4734  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11000/11807]  eta: 1:13:53  lr: 0.000010  loss: 1.8496  time: 5.4570  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11050/11807]  eta: 1:09:18  lr: 0.000010  loss: 2.8329  time: 5.4351  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11100/11807]  eta: 1:04:43  lr: 0.000010  loss: 2.2678  time: 5.5014  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11150/11807]  eta: 1:00:08  lr: 0.000010  loss: 2.1474  time: 5.5024  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11200/11807]  eta: 0:55:34  lr: 0.000010  loss: 2.0928  time: 5.5242  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11250/11807]  eta: 0:50:59  lr: 0.000010  loss: 2.1070  time: 5.5171  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11300/11807]  eta: 0:46:25  lr: 0.000010  loss: 2.0163  time: 5.5067  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11350/11807]  eta: 0:41:50  lr: 0.000010  loss: 2.2545  time: 5.5132  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11400/11807]  eta: 0:37:15  lr: 0.000010  loss: 2.4665  time: 5.5148  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11450/11807]  eta: 0:32:41  lr: 0.000010  loss: 2.2044  time: 5.4632  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11500/11807]  eta: 0:28:06  lr: 0.000010  loss: 2.4661  time: 5.4544  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11550/11807]  eta: 0:23:31  lr: 0.000010  loss: 2.3156  time: 5.5048  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11600/11807]  eta: 0:18:57  lr: 0.000010  loss: 2.0360  time: 5.4648  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11650/11807]  eta: 0:14:22  lr: 0.000010  loss: 1.8044  time: 5.4885  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11700/11807]  eta: 0:09:47  lr: 0.000010  loss: 2.3432  time: 5.4986  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11750/11807]  eta: 0:05:13  lr: 0.000010  loss: 1.5278  time: 5.4866  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11800/11807]  eta: 0:00:38  lr: 0.000010  loss: 1.8957  time: 5.4870  data: 0.0000  max mem: 14910
Train: data epoch: [0]  [11806/11807]  eta: 0:00:05  lr: 0.000010  loss: 1.8985  time: 5.4967  data: 0.0000  max mem: 14910
Train: data epoch: [0] Total time: 18:01:00 (5.4934 s / it)
2023-08-20 08:49:55,116 [INFO] Averaged stats: lr: 0.0000  loss: 2.1049
2023-08-20 08:49:55,169 [INFO] No validation splits found.
2023-08-20 08:49:55,224 [INFO] Saving checkpoint at epoch 0 to /public/home/mswanghao/TorchProject/lavis/lavis/output3/BLIP2/Caption_coco_drsl_0_20/20230819144/checkpoint_0.pth.
2023-08-20 08:49:59,268 [INFO] No validation splits found.
2023-08-20 08:49:59,268 [INFO] Training time 18:01:25
