WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
loss DRSL3 b=1e-05 start=0 end=20
loss DRSL3 b=1e-05 start=0 end=20
loss DRSL3 b=1e-05 start=0 end=20
loss DRSL3 b=1e-05 start=0 end=20
| distributed init (rank 1, world 4): env://
| distributed init (rank 2, world 4): env://| distributed init (rank 0, world 4): env://| distributed init (rank 3, world 4): env://


[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
2023-08-18 00:59:38,024 [INFO] 
=====  Running Parameters    =====
2023-08-18 00:59:38,027 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 2,
    "batch_size_train": 12,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1,
    "max_len": 30,
    "min_len": 8,
    "min_lr": 0,
    "num_beams": 5,
    "num_workers": 4,
    "output_dir": "output/BLIP2/Caption_coco_drsl_0_20",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "captioning",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "warmup_lr": 1e-08,
    "warmup_steps": 1000,
    "weight_decay": 0.05,
    "world_size": 4
}
2023-08-18 00:59:38,027 [INFO] 
======  Dataset Attributes  ======
2023-08-18 00:59:38,027 [INFO] 
======== coco_caption =======
2023-08-18 00:59:38,028 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a photo of "
        }
    },
    "vis_processor": {
        "eval": {
            "image_size": 364,
            "name": "blip_image_eval"
        },
        "train": {
            "image_size": 364,
            "name": "blip2_image_train"
        }
    }
}
2023-08-18 00:59:38,028 [INFO] 
======  Model Attributes  ======
2023-08-18 00:59:38,028 [INFO] {
    "arch": "blip2_opt",
    "drop_path_rate": 0,
    "freeze_vit": true,
    "image_size": 364,
    "load_finetuned": false,
    "model_type": "caption_coco_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth",
    "prompt": "a photo of",
    "use_grad_checkpoint": true,
    "vit_precision": "fp32"
}
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-08-18 00:59:38,082 [INFO] Building datasets...
BlipImageEvalProcessor
Position interpolate from 16x16 to 26x26
2023-08-18 01:00:31,677 [INFO] freeze vision encoder
2023-08-18 01:03:54,289 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth
2023-08-18 01:03:54,332 [INFO] Start training
2023-08-18 01:04:15,165 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-08-18 01:04:15,170 [INFO] Loaded 566747 records for train split from the dataset.
2023-08-18 01:04:15,170 [INFO] Loaded 5000 records for val split from the dataset.
2023-08-18 01:04:15,170 [INFO] Loaded 5000 records for test split from the dataset.
2023-08-18 01:04:15,220 [INFO] number of trainable parameters: 107133696
2023-08-18 01:04:15,227 [INFO] Start training epoch 0, 11807 iters per inner epoch.
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Train: data epoch: [0]  [    0/11807]  eta: 3 days, 11:55:36  lr: 0.000000  loss: 2.0367  time: 25.5896  data: 0.0000  max mem: 13105
2023-08-18 01:04:40,829 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [   50/11807]  eta: 17:42:04  lr: 0.000001  loss: 2.3927  time: 4.9920  data: 0.0000  max mem: 14868
Train: data epoch: [0]  [  100/11807]  eta: 17:28:50  lr: 0.000001  loss: 2.1089  time: 5.3747  data: 0.0000  max mem: 14868
Train: data epoch: [0]  [  150/11807]  eta: 17:19:00  lr: 0.000002  loss: 1.6541  time: 5.2640  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  200/11807]  eta: 17:12:31  lr: 0.000002  loss: 1.6331  time: 5.3422  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  250/11807]  eta: 17:05:15  lr: 0.000003  loss: 2.0303  time: 5.2515  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  300/11807]  eta: 17:00:08  lr: 0.000003  loss: 1.8268  time: 5.2571  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  350/11807]  eta: 16:54:23  lr: 0.000004  loss: 1.9645  time: 5.2606  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  400/11807]  eta: 16:49:27  lr: 0.000004  loss: 1.7779  time: 5.2572  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  450/11807]  eta: 16:44:23  lr: 0.000005  loss: 2.2172  time: 5.2545  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  500/11807]  eta: 16:39:19  lr: 0.000005  loss: 2.0274  time: 5.2747  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  550/11807]  eta: 16:34:33  lr: 0.000006  loss: 2.1155  time: 5.2847  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  600/11807]  eta: 16:29:41  lr: 0.000006  loss: 2.0438  time: 5.2632  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  650/11807]  eta: 16:24:46  lr: 0.000007  loss: 2.0833  time: 5.2548  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  700/11807]  eta: 16:20:13  lr: 0.000007  loss: 1.7002  time: 5.2936  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  750/11807]  eta: 16:15:09  lr: 0.000008  loss: 1.7078  time: 5.2450  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  800/11807]  eta: 16:10:34  lr: 0.000008  loss: 1.8101  time: 5.2597  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  850/11807]  eta: 16:06:12  lr: 0.000009  loss: 2.1479  time: 5.3199  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  900/11807]  eta: 16:01:47  lr: 0.000009  loss: 2.2576  time: 5.2648  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  950/11807]  eta: 15:56:56  lr: 0.000010  loss: 2.0197  time: 5.2637  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1000/11807]  eta: 15:52:15  lr: 0.000010  loss: 2.3918  time: 5.2634  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1050/11807]  eta: 15:47:53  lr: 0.000010  loss: 2.0666  time: 5.2794  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1100/11807]  eta: 15:43:16  lr: 0.000010  loss: 1.9389  time: 5.2736  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1150/11807]  eta: 15:38:57  lr: 0.000010  loss: 2.0761  time: 5.2795  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1200/11807]  eta: 15:34:17  lr: 0.000010  loss: 2.0012  time: 5.2772  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1250/11807]  eta: 15:29:40  lr: 0.000010  loss: 1.6639  time: 5.2469  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1300/11807]  eta: 15:25:10  lr: 0.000010  loss: 2.3985  time: 5.2905  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1350/11807]  eta: 15:20:45  lr: 0.000010  loss: 1.6870  time: 5.2978  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1400/11807]  eta: 15:16:17  lr: 0.000010  loss: 2.0527  time: 5.3070  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1450/11807]  eta: 15:11:38  lr: 0.000010  loss: 1.8579  time: 5.2597  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1500/11807]  eta: 15:07:08  lr: 0.000010  loss: 1.9554  time: 5.2309  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1550/11807]  eta: 15:02:37  lr: 0.000010  loss: 2.0718  time: 5.2203  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1600/11807]  eta: 14:57:57  lr: 0.000010  loss: 2.6672  time: 5.1944  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1650/11807]  eta: 14:53:26  lr: 0.000010  loss: 2.1833  time: 5.2386  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1700/11807]  eta: 14:49:04  lr: 0.000010  loss: 2.4152  time: 5.3053  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1750/11807]  eta: 14:44:35  lr: 0.000010  loss: 2.1693  time: 5.2574  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1800/11807]  eta: 14:40:08  lr: 0.000010  loss: 2.3894  time: 5.2262  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1850/11807]  eta: 14:35:47  lr: 0.000010  loss: 1.8597  time: 5.2883  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1900/11807]  eta: 14:31:23  lr: 0.000010  loss: 1.8599  time: 5.2838  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1950/11807]  eta: 14:27:01  lr: 0.000010  loss: 2.1913  time: 5.2898  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2000/11807]  eta: 14:22:35  lr: 0.000010  loss: 1.8813  time: 5.2596  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2050/11807]  eta: 14:18:16  lr: 0.000010  loss: 2.0250  time: 5.2789  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2100/11807]  eta: 14:13:51  lr: 0.000010  loss: 2.0136  time: 5.2946  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2150/11807]  eta: 14:09:25  lr: 0.000010  loss: 2.1673  time: 5.2440  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2200/11807]  eta: 14:04:56  lr: 0.000010  loss: 2.0465  time: 5.2534  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2250/11807]  eta: 14:00:33  lr: 0.000010  loss: 1.7987  time: 5.2575  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2300/11807]  eta: 13:56:09  lr: 0.000010  loss: 2.3615  time: 5.2608  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2350/11807]  eta: 13:51:43  lr: 0.000010  loss: 2.0941  time: 5.2690  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2400/11807]  eta: 13:47:18  lr: 0.000010  loss: 2.0944  time: 5.2905  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2450/11807]  eta: 13:42:56  lr: 0.000010  loss: 1.7972  time: 5.2663  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2500/11807]  eta: 13:38:34  lr: 0.000010  loss: 2.0136  time: 5.2794  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2550/11807]  eta: 13:34:06  lr: 0.000010  loss: 1.9884  time: 5.2441  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2600/11807]  eta: 13:29:40  lr: 0.000010  loss: 2.0657  time: 5.2693  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2650/11807]  eta: 13:25:19  lr: 0.000010  loss: 1.7695  time: 5.3135  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2700/11807]  eta: 13:20:56  lr: 0.000010  loss: 2.5057  time: 5.2639  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2750/11807]  eta: 13:16:32  lr: 0.000010  loss: 1.9127  time: 5.3052  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2800/11807]  eta: 13:12:09  lr: 0.000010  loss: 1.9700  time: 5.3131  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2850/11807]  eta: 13:07:41  lr: 0.000010  loss: 2.0085  time: 5.2597  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2900/11807]  eta: 13:03:13  lr: 0.000010  loss: 1.7478  time: 5.2264  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2950/11807]  eta: 12:58:47  lr: 0.000010  loss: 2.0695  time: 5.2283  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3000/11807]  eta: 12:54:26  lr: 0.000010  loss: 1.7479  time: 5.3046  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3050/11807]  eta: 12:50:05  lr: 0.000010  loss: 2.0818  time: 5.3143  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3100/11807]  eta: 12:45:47  lr: 0.000010  loss: 2.2931  time: 5.3057  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3150/11807]  eta: 12:41:18  lr: 0.000010  loss: 1.9221  time: 5.2457  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3200/11807]  eta: 12:36:56  lr: 0.000010  loss: 2.2931  time: 5.3077  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3250/11807]  eta: 12:32:34  lr: 0.000010  loss: 2.4476  time: 5.3025  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3300/11807]  eta: 12:28:11  lr: 0.000010  loss: 2.0793  time: 5.2692  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3350/11807]  eta: 12:23:49  lr: 0.000010  loss: 1.9785  time: 5.3163  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3400/11807]  eta: 12:19:02  lr: 0.000010  loss: 2.4689  time: 5.0372  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3450/11807]  eta: 12:14:09  lr: 0.000010  loss: 2.2337  time: 5.0070  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3500/11807]  eta: 12:09:17  lr: 0.000010  loss: 2.1183  time: 5.0333  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3550/11807]  eta: 12:04:24  lr: 0.000010  loss: 2.1020  time: 5.0083  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3600/11807]  eta: 11:59:31  lr: 0.000010  loss: 2.0766  time: 5.0097  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3650/11807]  eta: 11:54:40  lr: 0.000010  loss: 1.9066  time: 5.0332  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3700/11807]  eta: 11:49:50  lr: 0.000010  loss: 1.9294  time: 4.9927  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3750/11807]  eta: 11:44:59  lr: 0.000010  loss: 2.5409  time: 4.9935  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3800/11807]  eta: 11:40:10  lr: 0.000010  loss: 1.8395  time: 4.9885  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3850/11807]  eta: 11:35:22  lr: 0.000010  loss: 2.1028  time: 4.9749  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3900/11807]  eta: 11:30:36  lr: 0.000010  loss: 1.7412  time: 4.9862  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3950/11807]  eta: 11:25:52  lr: 0.000010  loss: 2.0310  time: 5.0153  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4000/11807]  eta: 11:21:09  lr: 0.000010  loss: 2.1004  time: 4.9977  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4050/11807]  eta: 11:16:28  lr: 0.000010  loss: 2.1485  time: 5.0230  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4100/11807]  eta: 11:11:45  lr: 0.000010  loss: 1.8956  time: 5.0088  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4150/11807]  eta: 11:07:02  lr: 0.000010  loss: 2.2042  time: 4.9921  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4200/11807]  eta: 11:02:23  lr: 0.000010  loss: 2.0255  time: 5.0237  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4250/11807]  eta: 10:57:42  lr: 0.000010  loss: 2.0007  time: 4.9822  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4300/11807]  eta: 10:53:01  lr: 0.000010  loss: 2.3947  time: 5.0009  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4350/11807]  eta: 10:48:22  lr: 0.000010  loss: 2.2552  time: 5.0214  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4400/11807]  eta: 10:43:45  lr: 0.000010  loss: 2.2261  time: 5.0123  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4450/11807]  eta: 10:39:05  lr: 0.000010  loss: 2.0345  time: 4.9673  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4500/11807]  eta: 10:34:28  lr: 0.000010  loss: 2.0511  time: 5.0101  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4550/11807]  eta: 10:29:52  lr: 0.000010  loss: 2.2779  time: 5.0117  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4600/11807]  eta: 10:25:17  lr: 0.000010  loss: 2.3269  time: 5.0141  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4650/11807]  eta: 10:20:40  lr: 0.000010  loss: 2.0497  time: 4.9617  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4700/11807]  eta: 10:16:04  lr: 0.000010  loss: 2.1802  time: 4.9802  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4750/11807]  eta: 10:11:30  lr: 0.000010  loss: 2.3231  time: 5.0293  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4800/11807]  eta: 10:06:55  lr: 0.000010  loss: 2.1611  time: 4.9729  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4850/11807]  eta: 10:02:21  lr: 0.000010  loss: 1.8842  time: 4.9905  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4900/11807]  eta: 9:57:49  lr: 0.000010  loss: 2.2765  time: 4.9957  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4950/11807]  eta: 9:53:15  lr: 0.000010  loss: 2.1099  time: 4.9686  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5000/11807]  eta: 9:48:44  lr: 0.000010  loss: 2.3572  time: 5.0198  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5050/11807]  eta: 9:44:13  lr: 0.000010  loss: 1.7748  time: 4.9905  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5100/11807]  eta: 9:39:42  lr: 0.000010  loss: 2.2909  time: 4.9921  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5150/11807]  eta: 9:35:12  lr: 0.000010  loss: 1.9321  time: 5.0438  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5200/11807]  eta: 9:30:40  lr: 0.000010  loss: 1.7750  time: 4.9862  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5250/11807]  eta: 9:26:09  lr: 0.000010  loss: 1.9570  time: 4.9743  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5300/11807]  eta: 9:21:39  lr: 0.000010  loss: 2.4831  time: 4.9887  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5350/11807]  eta: 9:17:10  lr: 0.000010  loss: 1.8810  time: 4.9945  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5400/11807]  eta: 9:12:42  lr: 0.000010  loss: 2.4306  time: 5.0413  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5450/11807]  eta: 9:08:14  lr: 0.000010  loss: 2.3227  time: 5.0289  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5500/11807]  eta: 9:03:46  lr: 0.000010  loss: 2.1453  time: 5.0281  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5550/11807]  eta: 8:59:19  lr: 0.000010  loss: 2.5624  time: 5.0090  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5600/11807]  eta: 8:54:50  lr: 0.000010  loss: 1.9361  time: 5.0055  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5650/11807]  eta: 8:50:22  lr: 0.000010  loss: 1.7102  time: 4.9724  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5700/11807]  eta: 8:45:56  lr: 0.000010  loss: 2.1712  time: 5.0128  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5750/11807]  eta: 8:41:30  lr: 0.000010  loss: 2.2288  time: 5.0093  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5800/11807]  eta: 8:37:04  lr: 0.000010  loss: 2.0867  time: 5.0365  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5850/11807]  eta: 8:32:37  lr: 0.000010  loss: 1.9495  time: 5.0005  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5900/11807]  eta: 8:28:12  lr: 0.000010  loss: 2.3874  time: 5.0054  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5950/11807]  eta: 8:23:46  lr: 0.000010  loss: 2.0749  time: 4.9945  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6000/11807]  eta: 8:19:20  lr: 0.000010  loss: 2.5206  time: 5.0187  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6050/11807]  eta: 8:14:55  lr: 0.000010  loss: 2.3710  time: 4.9973  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6100/11807]  eta: 8:10:29  lr: 0.000010  loss: 2.3965  time: 4.9707  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6150/11807]  eta: 8:06:05  lr: 0.000010  loss: 2.0965  time: 5.0003  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6200/11807]  eta: 8:01:40  lr: 0.000010  loss: 1.9458  time: 5.0165  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6250/11807]  eta: 7:57:16  lr: 0.000010  loss: 1.7882  time: 4.9837  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6300/11807]  eta: 7:52:52  lr: 0.000010  loss: 1.5995  time: 5.0133  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6350/11807]  eta: 7:48:29  lr: 0.000010  loss: 2.1746  time: 5.0375  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6400/11807]  eta: 7:44:05  lr: 0.000010  loss: 2.3911  time: 5.0107  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6450/11807]  eta: 7:39:42  lr: 0.000010  loss: 2.2465  time: 4.9967  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6500/11807]  eta: 7:35:19  lr: 0.000010  loss: 2.0020  time: 5.0149  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6550/11807]  eta: 7:30:55  lr: 0.000010  loss: 1.7793  time: 4.9847  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6600/11807]  eta: 7:26:33  lr: 0.000010  loss: 1.6291  time: 4.9761  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6650/11807]  eta: 7:22:10  lr: 0.000010  loss: 2.0407  time: 5.0336  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6700/11807]  eta: 7:17:48  lr: 0.000010  loss: 2.3125  time: 5.0000  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6750/11807]  eta: 7:13:26  lr: 0.000010  loss: 2.0036  time: 4.9861  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6800/11807]  eta: 7:09:03  lr: 0.000010  loss: 2.0827  time: 5.0004  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6850/11807]  eta: 7:04:41  lr: 0.000010  loss: 2.2911  time: 5.0108  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6900/11807]  eta: 7:00:20  lr: 0.000010  loss: 1.9527  time: 5.0318  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6950/11807]  eta: 6:55:58  lr: 0.000010  loss: 1.9350  time: 4.9924  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7000/11807]  eta: 6:51:37  lr: 0.000010  loss: 1.9173  time: 5.0506  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7050/11807]  eta: 6:47:16  lr: 0.000010  loss: 1.8508  time: 4.9946  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7100/11807]  eta: 6:42:55  lr: 0.000010  loss: 1.8316  time: 5.0063  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7150/11807]  eta: 6:38:33  lr: 0.000010  loss: 2.2004  time: 4.9614  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7200/11807]  eta: 6:34:12  lr: 0.000010  loss: 1.7276  time: 5.0321  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7250/11807]  eta: 6:29:52  lr: 0.000010  loss: 1.9323  time: 5.0151  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7300/11807]  eta: 6:25:31  lr: 0.000010  loss: 2.0205  time: 5.0094  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7350/11807]  eta: 6:21:11  lr: 0.000010  loss: 1.8299  time: 5.0202  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7400/11807]  eta: 6:16:50  lr: 0.000010  loss: 1.8741  time: 4.9774  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7450/11807]  eta: 6:12:30  lr: 0.000010  loss: 2.1017  time: 5.0113  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7500/11807]  eta: 6:08:09  lr: 0.000010  loss: 2.1483  time: 5.0052  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7550/11807]  eta: 6:03:50  lr: 0.000010  loss: 1.9861  time: 5.0007  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7600/11807]  eta: 5:59:29  lr: 0.000010  loss: 2.3942  time: 4.9929  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7650/11807]  eta: 5:55:10  lr: 0.000010  loss: 2.3079  time: 5.0380  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7700/11807]  eta: 5:50:51  lr: 0.000010  loss: 1.7635  time: 5.0351  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7750/11807]  eta: 5:46:32  lr: 0.000010  loss: 2.3186  time: 5.0446  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7800/11807]  eta: 5:42:13  lr: 0.000010  loss: 2.1250  time: 4.9753  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7850/11807]  eta: 5:37:53  lr: 0.000010  loss: 1.8621  time: 5.0120  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7900/11807]  eta: 5:33:35  lr: 0.000010  loss: 2.4235  time: 5.0380  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7950/11807]  eta: 5:29:16  lr: 0.000010  loss: 2.4105  time: 5.0197  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8000/11807]  eta: 5:24:57  lr: 0.000010  loss: 2.2530  time: 4.9795  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8050/11807]  eta: 5:20:38  lr: 0.000010  loss: 2.4678  time: 5.0285  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8100/11807]  eta: 5:16:20  lr: 0.000010  loss: 1.6857  time: 4.9980  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8150/11807]  eta: 5:12:01  lr: 0.000010  loss: 2.4050  time: 4.9923  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8200/11807]  eta: 5:07:43  lr: 0.000010  loss: 2.3286  time: 5.0029  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8250/11807]  eta: 5:03:25  lr: 0.000010  loss: 2.3099  time: 5.0549  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8300/11807]  eta: 4:59:07  lr: 0.000010  loss: 2.0204  time: 4.9886  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8350/11807]  eta: 4:54:48  lr: 0.000010  loss: 2.1996  time: 5.0081  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8400/11807]  eta: 4:50:30  lr: 0.000010  loss: 2.0667  time: 5.0032  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8450/11807]  eta: 4:46:13  lr: 0.000010  loss: 2.4895  time: 5.0238  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8500/11807]  eta: 4:41:55  lr: 0.000010  loss: 1.8250  time: 4.9910  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8550/11807]  eta: 4:37:37  lr: 0.000010  loss: 2.3973  time: 5.0075  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8600/11807]  eta: 4:33:20  lr: 0.000010  loss: 2.1156  time: 5.0532  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8650/11807]  eta: 4:29:02  lr: 0.000010  loss: 2.3557  time: 4.9793  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8700/11807]  eta: 4:24:44  lr: 0.000010  loss: 2.3120  time: 5.0123  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8750/11807]  eta: 4:20:27  lr: 0.000010  loss: 2.1797  time: 5.0390  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8800/11807]  eta: 4:16:09  lr: 0.000010  loss: 2.1015  time: 4.9996  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8850/11807]  eta: 4:11:52  lr: 0.000010  loss: 1.7005  time: 4.9822  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8900/11807]  eta: 4:07:35  lr: 0.000010  loss: 1.8652  time: 4.9978  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8950/11807]  eta: 4:03:17  lr: 0.000010  loss: 2.0318  time: 5.0213  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9000/11807]  eta: 3:59:00  lr: 0.000010  loss: 2.3799  time: 4.9937  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9050/11807]  eta: 3:54:44  lr: 0.000010  loss: 2.1871  time: 5.0089  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9100/11807]  eta: 3:50:26  lr: 0.000010  loss: 2.0944  time: 4.9756  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9150/11807]  eta: 3:46:09  lr: 0.000010  loss: 2.0205  time: 4.9910  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9200/11807]  eta: 3:41:52  lr: 0.000010  loss: 1.6898  time: 4.9656  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9250/11807]  eta: 3:37:36  lr: 0.000010  loss: 2.2706  time: 5.0089  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9300/11807]  eta: 3:33:19  lr: 0.000010  loss: 1.9061  time: 5.0076  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9350/11807]  eta: 3:29:03  lr: 0.000010  loss: 2.0699  time: 4.9562  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9400/11807]  eta: 3:24:47  lr: 0.000010  loss: 2.0991  time: 5.0291  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9450/11807]  eta: 3:20:30  lr: 0.000010  loss: 2.0059  time: 5.0092  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9500/11807]  eta: 3:16:14  lr: 0.000010  loss: 2.4322  time: 5.0007  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9550/11807]  eta: 3:11:57  lr: 0.000010  loss: 2.1024  time: 4.9685  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9600/11807]  eta: 3:07:41  lr: 0.000010  loss: 1.8687  time: 4.9940  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9650/11807]  eta: 3:03:25  lr: 0.000010  loss: 1.8371  time: 5.0401  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9700/11807]  eta: 2:59:09  lr: 0.000010  loss: 1.7999  time: 4.9945  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9750/11807]  eta: 2:54:53  lr: 0.000010  loss: 2.4819  time: 4.9923  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9800/11807]  eta: 2:50:36  lr: 0.000010  loss: 2.2593  time: 5.0067  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9850/11807]  eta: 2:46:21  lr: 0.000010  loss: 2.2932  time: 4.9968  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9900/11807]  eta: 2:42:05  lr: 0.000010  loss: 2.1008  time: 4.9900  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9950/11807]  eta: 2:37:49  lr: 0.000010  loss: 1.9751  time: 5.0190  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10000/11807]  eta: 2:33:33  lr: 0.000010  loss: 2.2416  time: 5.0141  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10050/11807]  eta: 2:29:17  lr: 0.000010  loss: 1.9318  time: 5.0129  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10100/11807]  eta: 2:25:01  lr: 0.000010  loss: 2.0464  time: 5.0232  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10150/11807]  eta: 2:20:46  lr: 0.000010  loss: 2.2237  time: 4.9956  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10200/11807]  eta: 2:16:30  lr: 0.000010  loss: 1.7644  time: 5.0026  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10250/11807]  eta: 2:12:15  lr: 0.000010  loss: 2.1558  time: 5.0057  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10300/11807]  eta: 2:07:59  lr: 0.000010  loss: 2.3136  time: 4.9973  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10350/11807]  eta: 2:03:43  lr: 0.000010  loss: 2.1162  time: 4.9611  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10400/11807]  eta: 1:59:28  lr: 0.000010  loss: 2.2704  time: 5.0023  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10450/11807]  eta: 1:55:13  lr: 0.000010  loss: 1.8248  time: 5.0129  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10500/11807]  eta: 1:50:58  lr: 0.000010  loss: 1.8917  time: 5.0201  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10550/11807]  eta: 1:46:42  lr: 0.000010  loss: 2.4967  time: 5.0207  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10600/11807]  eta: 1:42:27  lr: 0.000010  loss: 2.3014  time: 4.9763  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10650/11807]  eta: 1:38:12  lr: 0.000010  loss: 2.0903  time: 5.0368  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10700/11807]  eta: 1:33:57  lr: 0.000010  loss: 2.2295  time: 5.0407  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10750/11807]  eta: 1:29:42  lr: 0.000010  loss: 1.9242  time: 5.0262  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10800/11807]  eta: 1:25:27  lr: 0.000010  loss: 2.0963  time: 5.0257  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10850/11807]  eta: 1:21:12  lr: 0.000010  loss: 2.3749  time: 5.0029  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10900/11807]  eta: 1:16:57  lr: 0.000010  loss: 2.2425  time: 5.0428  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10950/11807]  eta: 1:12:42  lr: 0.000010  loss: 1.8912  time: 4.9722  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11000/11807]  eta: 1:08:27  lr: 0.000010  loss: 1.8496  time: 5.0249  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11050/11807]  eta: 1:04:12  lr: 0.000010  loss: 2.8329  time: 4.9980  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11100/11807]  eta: 0:59:58  lr: 0.000010  loss: 2.2678  time: 5.0606  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11150/11807]  eta: 0:55:43  lr: 0.000010  loss: 2.1474  time: 4.9855  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11200/11807]  eta: 0:51:28  lr: 0.000010  loss: 2.0928  time: 5.0256  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11250/11807]  eta: 0:47:14  lr: 0.000010  loss: 2.1070  time: 5.0131  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11300/11807]  eta: 0:42:59  lr: 0.000010  loss: 2.0163  time: 5.0118  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11350/11807]  eta: 0:38:45  lr: 0.000010  loss: 2.2545  time: 5.0160  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11400/11807]  eta: 0:34:30  lr: 0.000010  loss: 2.4665  time: 5.0177  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11450/11807]  eta: 0:30:16  lr: 0.000010  loss: 2.2044  time: 4.9995  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11500/11807]  eta: 0:26:01  lr: 0.000010  loss: 2.4661  time: 4.9850  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11550/11807]  eta: 0:21:47  lr: 0.000010  loss: 2.3156  time: 5.0202  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11600/11807]  eta: 0:17:32  lr: 0.000010  loss: 2.0360  time: 4.9706  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11650/11807]  eta: 0:13:18  lr: 0.000010  loss: 1.8044  time: 4.9817  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11700/11807]  eta: 0:09:04  lr: 0.000010  loss: 2.3432  time: 4.9884  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11750/11807]  eta: 0:04:49  lr: 0.000010  loss: 1.5278  time: 5.0137  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11800/11807]  eta: 0:00:35  lr: 0.000010  loss: 1.8957  time: 4.9899  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11806/11807]  eta: 0:00:05  lr: 0.000010  loss: 1.8985  time: 5.0023  data: 0.0000  max mem: 14911
Train: data epoch: [0] Total time: 16:40:32 (5.0845 s / it)
2023-08-18 17:44:47,726 [INFO] Averaged stats: lr: 0.0000  loss: 2.1049
2023-08-18 17:44:47,787 [INFO] Evaluating on val.
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
Evaluation  [  0/625]  eta: 1:08:40    time: 6.5930  data: 0.5996  max mem: 14911
Evaluation  [ 10/625]  eta: 0:41:50    time: 4.0825  data: 0.0554  max mem: 14911
Evaluation  [ 20/625]  eta: 0:41:04    time: 3.9469  data: 0.0009  max mem: 14911
Evaluation  [ 30/625]  eta: 0:39:42    time: 3.9601  data: 0.0009  max mem: 14911
Evaluation  [ 40/625]  eta: 0:38:53    time: 3.9014  data: 0.0011  max mem: 14911
Evaluation  [ 50/625]  eta: 0:38:19    time: 3.9919  data: 0.0010  max mem: 14911
Evaluation  [ 60/625]  eta: 0:37:19    time: 3.9131  data: 0.0008  max mem: 14911
Evaluation  [ 70/625]  eta: 0:36:45    time: 3.9068  data: 0.0007  max mem: 14911
Evaluation  [ 80/625]  eta: 0:36:05    time: 4.0035  data: 0.0008  max mem: 14911
Evaluation  [ 90/625]  eta: 0:35:37    time: 4.0764  data: 0.0008  max mem: 14911
Evaluation  [100/625]  eta: 0:34:53    time: 4.0464  data: 0.0008  max mem: 14911
Evaluation  [110/625]  eta: 0:34:07    time: 3.8891  data: 0.0007  max mem: 14911
Evaluation  [120/625]  eta: 0:33:28    time: 3.9213  data: 0.0008  max mem: 14911
Evaluation  [130/625]  eta: 0:32:58    time: 4.1062  data: 0.0008  max mem: 14911
Evaluation  [140/625]  eta: 0:32:09    time: 3.9883  data: 0.0009  max mem: 14911
Evaluation  [150/625]  eta: 0:31:28    time: 3.8388  data: 0.0010  max mem: 14911
Evaluation  [160/625]  eta: 0:30:49    time: 3.9752  data: 0.0009  max mem: 14911
Evaluation  [170/625]  eta: 0:30:08    time: 3.9653  data: 0.0008  max mem: 14911
Evaluation  [180/625]  eta: 0:29:29    time: 3.9580  data: 0.0008  max mem: 14911
Evaluation  [190/625]  eta: 0:28:55    time: 4.1139  data: 0.0026  max mem: 14911
Evaluation  [200/625]  eta: 0:28:21    time: 4.2540  data: 0.0026  max mem: 14911
Evaluation  [210/625]  eta: 0:27:40    time: 4.1189  data: 0.0009  max mem: 14911
Evaluation  [220/625]  eta: 0:26:54    time: 3.8072  data: 0.0009  max mem: 14911
Evaluation  [230/625]  eta: 0:26:18    time: 3.9406  data: 0.0008  max mem: 14911
Evaluation  [240/625]  eta: 0:25:36    time: 4.0415  data: 0.0008  max mem: 14911
Evaluation  [250/625]  eta: 0:24:58    time: 3.9881  data: 0.0008  max mem: 14911
Evaluation  [260/625]  eta: 0:24:15    time: 3.9428  data: 0.0007  max mem: 14911
Evaluation  [270/625]  eta: 0:23:36    time: 3.9163  data: 0.0007  max mem: 14911
Evaluation  [280/625]  eta: 0:23:00    time: 4.1805  data: 0.0008  max mem: 14911
Evaluation  [290/625]  eta: 0:22:25    time: 4.3686  data: 0.0008  max mem: 14911
Evaluation  [300/625]  eta: 0:21:47    time: 4.3242  data: 0.0007  max mem: 14911
Evaluation  [310/625]  eta: 0:21:06    time: 4.1037  data: 0.0008  max mem: 14911
Evaluation  [320/625]  eta: 0:20:25    time: 3.9408  data: 0.0009  max mem: 14911
Evaluation  [330/625]  eta: 0:19:42    time: 3.8166  data: 0.0008  max mem: 14911
Evaluation  [340/625]  eta: 0:19:04    time: 3.9940  data: 0.0008  max mem: 14911
Evaluation  [350/625]  eta: 0:18:24    time: 4.1462  data: 0.0008  max mem: 14911
Evaluation  [360/625]  eta: 0:17:43    time: 3.9462  data: 0.0008  max mem: 14911
Evaluation  [370/625]  eta: 0:17:06    time: 4.1521  data: 0.0012  max mem: 14911
Evaluation  [380/625]  eta: 0:16:25    time: 4.2020  data: 0.0012  max mem: 14911
Evaluation  [390/625]  eta: 0:15:45    time: 3.9911  data: 0.0009  max mem: 14911
Evaluation  [400/625]  eta: 0:15:03    time: 3.9141  data: 0.0009  max mem: 14911
Evaluation  [410/625]  eta: 0:14:22    time: 3.7916  data: 0.0009  max mem: 14911
Evaluation  [420/625]  eta: 0:13:41    time: 3.8627  data: 0.0009  max mem: 14911
Evaluation  [430/625]  eta: 0:13:02    time: 4.0471  data: 0.0008  max mem: 14911
Evaluation  [440/625]  eta: 0:12:21    time: 3.9304  data: 0.0008  max mem: 14911
Evaluation  [450/625]  eta: 0:11:39    time: 3.6409  data: 0.0008  max mem: 14911
Evaluation  [460/625]  eta: 0:10:59    time: 3.8200  data: 0.0010  max mem: 14911
Evaluation  [470/625]  eta: 0:10:19    time: 4.0788  data: 0.0010  max mem: 14911
Evaluation  [480/625]  eta: 0:09:38    time: 3.8549  data: 0.0007  max mem: 14911
Evaluation  [490/625]  eta: 0:08:58    time: 3.7695  data: 0.0010  max mem: 14911
Evaluation  [500/625]  eta: 0:08:19    time: 4.0711  data: 0.0010  max mem: 14911
Evaluation  [510/625]  eta: 0:07:39    time: 4.0151  data: 0.0007  max mem: 14911
Evaluation  [520/625]  eta: 0:06:58    time: 3.8054  data: 0.0007  max mem: 14911
Evaluation  [530/625]  eta: 0:06:18    time: 3.9220  data: 0.0010  max mem: 14911
Evaluation  [540/625]  eta: 0:05:38    time: 3.9542  data: 0.0011  max mem: 14911
Evaluation  [550/625]  eta: 0:04:58    time: 3.9119  data: 0.0009  max mem: 14911
Evaluation  [560/625]  eta: 0:04:19    time: 3.9519  data: 0.0010  max mem: 14911
Evaluation  [570/625]  eta: 0:03:39    time: 3.9631  data: 0.0008  max mem: 14911
Evaluation  [580/625]  eta: 0:02:59    time: 4.1326  data: 0.0008  max mem: 14911
Evaluation  [590/625]  eta: 0:02:19    time: 4.1906  data: 0.0009  max mem: 14911
Evaluation  [600/625]  eta: 0:01:39    time: 4.0659  data: 0.0009  max mem: 14911
Evaluation  [610/625]  eta: 0:00:59    time: 4.0539  data: 0.0009  max mem: 14911
Evaluation  [620/625]  eta: 0:00:19    time: 4.0643  data: 0.0008  max mem: 14911
Evaluation  [624/625]  eta: 0:00:03    time: 3.9916  data: 0.0034  max mem: 14911
Evaluation Total time: 0:41:35 (3.9924 s / it)
2023-08-18 18:26:59,665 [WARNING] rank 0 starts merging results.
result file saved to /public/home/mswanghao/TorchProject/lavis/lavis/output/BLIP2/Caption_coco_drsl_0_20/20230818005/result/val_epoch0.json
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:13 │
│ 46 in do_open                                                                │
│                                                                              │
│   1343 │   │                                                                 │
│   1344 │   │   try:                                                          │
│   1345 │   │   │   try:                                                      │
│ ❱ 1346 │   │   │   │   h.request(req.get_method(), req.selector, req.data, h │
│   1347 │   │   │   │   │   │     encode_chunked=req.has_header('Transfer-enc │
│   1348 │   │   │   except OSError as err: # timeout error                    │
│   1349 │   │   │   │   raise URLError(err)                                   │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1285  │
│ in request                                                                   │
│                                                                              │
│   1282 │   def request(self, method, url, body=None, headers={}, *,          │
│   1283 │   │   │   │   encode_chunked=False):                                │
│   1284 │   │   """Send a complete request to the server."""                  │
│ ❱ 1285 │   │   self._send_request(method, url, body, headers, encode_chunked │
│   1286 │                                                                     │
│   1287 │   def _send_request(self, method, url, body, headers, encode_chunke │
│   1288 │   │   # Honor explicitly requested Host: and Accept-Encoding: heade │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1331  │
│ in _send_request                                                             │
│                                                                              │
│   1328 │   │   │   # RFC 2616 Section 3.7.1 says that text default has a     │
│   1329 │   │   │   # default charset of iso-8859-1.                          │
│   1330 │   │   │   body = _encode(body, 'body')                              │
│ ❱ 1331 │   │   self.endheaders(body, encode_chunked=encode_chunked)          │
│   1332 │                                                                     │
│   1333 │   def getresponse(self):                                            │
│   1334 │   │   """Get the response from the server.                          │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1280  │
│ in endheaders                                                                │
│                                                                              │
│   1277 │   │   │   self.__state = _CS_REQ_SENT                               │
│   1278 │   │   else:                                                         │
│   1279 │   │   │   raise CannotSendHeader()                                  │
│ ❱ 1280 │   │   self._send_output(message_body, encode_chunked=encode_chunked │
│   1281 │                                                                     │
│   1282 │   def request(self, method, url, body=None, headers={}, *,          │
│   1283 │   │   │   │   encode_chunked=False):                                │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1040  │
│ in _send_output                                                              │
│                                                                              │
│   1037 │   │   self._buffer.extend((b"", b""))                               │
│   1038 │   │   msg = b"\r\n".join(self._buffer)                              │
│   1039 │   │   del self._buffer[:]                                           │
│ ❱ 1040 │   │   self.send(msg)                                                │
│   1041 │   │                                                                 │
│   1042 │   │   if message_body is not None:                                  │
│   1043                                                                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:980   │
│ in send                                                                      │
│                                                                              │
│    977 │   │                                                                 │
│    978 │   │   if self.sock is None:                                         │
│    979 │   │   │   if self.auto_open:                                        │
│ ❱  980 │   │   │   │   self.connect()                                        │
│    981 │   │   │   else:                                                     │
│    982 │   │   │   │   raise NotConnected()                                  │
│    983                                                                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1447  │
│ in connect                                                                   │
│                                                                              │
│   1444 │   │   def connect(self):                                            │
│   1445 │   │   │   "Connect to a host on a given (SSL) port."                │
│   1446 │   │   │                                                             │
│ ❱ 1447 │   │   │   super().connect()                                         │
│   1448 │   │   │                                                             │
│   1449 │   │   │   if self._tunnel_host:                                     │
│   1450 │   │   │   │   server_hostname = self._tunnel_host                   │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:946   │
│ in connect                                                                   │
│                                                                              │
│    943 │                                                                     │
│    944 │   def connect(self):                                                │
│    945 │   │   """Connect to the host and port specified in __init__."""     │
│ ❱  946 │   │   self.sock = self._create_connection(                          │
│    947 │   │   │   (self.host,self.port), self.timeout, self.source_address) │
│    948 │   │   # Might fail in OSs that don't implement TCP_NODELAY          │
│    949 │   │   try:                                                          │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/socket.py:823 in     │
│ create_connection                                                            │
│                                                                              │
│   820 │                                                                      │
│   821 │   host, port = address                                               │
│   822 │   err = None                                                         │
│ ❱ 823 │   for res in getaddrinfo(host, port, 0, SOCK_STREAM):                │
│   824 │   │   af, socktype, proto, canonname, sa = res                       │
│   825 │   │   sock = None                                                    │
│   826 │   │   try:                                                           │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/socket.py:954 in     │
│ getaddrinfo                                                                  │
│                                                                              │
│   951 │   # We override this function since we want to translate the numeric │
│   952 │   # and socket type values to enum constants.                        │
│   953 │   addrlist = []                                                      │
│ ❱ 954 │   for res in _socket.getaddrinfo(host, port, family, type, proto, fl │
│   955 │   │   af, socktype, proto, canonname, sa = res                       │
│   956 │   │   addrlist.append((_intenum_converter(af, AddressFamily),        │
│   957 │   │   │   │   │   │    _intenum_converter(socktype, SocketKind),     │
╰──────────────────────────────────────────────────────────────────────────────╯
gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /public/home/mswanghao/TorchProject/lavis/train.py:116 in <module>           │
│                                                                              │
│   113                                                                        │
│   114                                                                        │
│   115 if __name__ == "__main__":                                             │
│ ❱ 116 │   main()                                                             │
│   117                                                                        │
│   118                                                                        │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/train.py:112 in main               │
│                                                                              │
│   109 │   runner = get_runner_class(cfg)(                                    │
│   110 │   │   cfg=cfg, job_id=job_id, task=task, model=model, datasets=datas │
│   111 │   )                                                                  │
│ ❱ 112 │   runner.train()                                                     │
│   113                                                                        │
│   114                                                                        │
│   115 if __name__ == "__main__":                                             │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/runners/runner_base.py:380   │
│ in train                                                                     │
│                                                                              │
│   377 │   │   │   │   for split_name in self.valid_splits:                   │
│   378 │   │   │   │   │   logging.info("Evaluating on {}.".format(split_name │
│   379 │   │   │   │   │                                                      │
│ ❱ 380 │   │   │   │   │   val_log = self.eval_epoch(                         │
│   381 │   │   │   │   │   │   split_name=split_name, cur_epoch=cur_epoch     │
│   382 │   │   │   │   │   )                                                  │
│   383 │   │   │   │   │   if val_log is not None:                            │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/ │
│ autograd/grad_mode.py:28 in decorate_context                                 │
│                                                                              │
│    25 │   │   @functools.wraps(func)                                         │
│    26 │   │   def decorate_context(*args, **kwargs):                         │
│    27 │   │   │   with self.__class__():                                     │
│ ❱  28 │   │   │   │   return func(*args, **kwargs)                           │
│    29 │   │   return cast(F, decorate_context)                               │
│    30 │                                                                      │
│    31 │   def _wrap_generator(self, func):                                   │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/runners/runner_base.py:472   │
│ in eval_epoch                                                                │
│                                                                              │
│   469 │   │   results = self.task.evaluation(model, data_loader)             │
│   470 │   │                                                                  │
│   471 │   │   if results is not None:                                        │
│ ❱ 472 │   │   │   return self.task.after_evaluation(                         │
│   473 │   │   │   │   val_result=results,                                    │
│   474 │   │   │   │   split_name=split_name,                                 │
│   475 │   │   │   │   epoch=cur_epoch,                                       │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/tasks/captioning.py:74 in    │
│ after_evaluation                                                             │
│                                                                              │
│    71 │   │   )                                                              │
│    72 │   │                                                                  │
│    73 │   │   if self.report_metric:                                         │
│ ❱  74 │   │   │   metrics = self._report_metrics(                            │
│    75 │   │   │   │   eval_result_file=eval_result_file, split_name=split_na │
│    76 │   │   │   )                                                          │
│    77 │   │   else:                                                          │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/common/dist_utils.py:112 in  │
│ wrapper                                                                      │
│                                                                              │
│   109 │   def wrapper(*args, **kwargs):                                      │
│   110 │   │   rank, _ = get_dist_info()                                      │
│   111 │   │   if rank == 0:                                                  │
│ ❱ 112 │   │   │   return func(*args, **kwargs)                               │
│   113 │                                                                      │
│   114 │   return wrapper                                                     │
│   115                                                                        │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/tasks/captioning.py:87 in    │
│ _report_metrics                                                              │
│                                                                              │
│    84 │   │                                                                  │
│    85 │   │   # TODO better way to define this                               │
│    86 │   │   coco_gt_root = os.path.join(registry.get_path("cache_root"), " │
│ ❱  87 │   │   coco_val = coco_caption_eval(coco_gt_root, eval_result_file, s │
│    88 │   │                                                                  │
│    89 │   │   agg_metrics = coco_val.eval["CIDEr"] + coco_val.eval["Bleu_4"] │
│    90 │   │   log_stats = {split_name: {k: v for k, v in coco_val.eval.items │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/tasks/captioning.py:119 in   │
│ coco_caption_eval                                                            │
│                                                                              │
│   116 │   │   "test": "coco_karpathy_test_gt.json",                          │
│   117 │   }                                                                  │
│   118 │                                                                      │
│ ❱ 119 │   download_url(urls[split], coco_gt_root)                            │
│   120 │   annotation_file = os.path.join(coco_gt_root, filenames[split])     │
│   121 │                                                                      │
│   122 │   # create coco object and coco_result object                        │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torchv │
│ ision/datasets/utils.py:129 in download_url                                  │
│                                                                              │
│   126 │   │   _download_file_from_remote_location(fpath, url)                │
│   127 │   else:                                                              │
│   128 │   │   # expand redirect chain if needed                              │
│ ❱ 129 │   │   url = _get_redirect_url(url, max_hops=max_redirect_hops)       │
│   130 │   │                                                                  │
│   131 │   │   # check if file is located on Google Drive                     │
│   132 │   │   file_id = _get_google_drive_file_id(url)                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torchv │
│ ision/datasets/utils.py:77 in _get_redirect_url                              │
│                                                                              │
│    74 │   headers = {"Method": "HEAD", "User-Agent": USER_AGENT}             │
│    75 │                                                                      │
│    76 │   for _ in range(max_hops + 1):                                      │
│ ❱  77 │   │   with urllib.request.urlopen(urllib.request.Request(url, header │
│    78 │   │   │   if response.url == url or response.url is None:            │
│    79 │   │   │   │   return url                                             │
│    80                                                                        │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:21 │
│ 4 in urlopen                                                                 │
│                                                                              │
│    211 │   │   _opener = opener = build_opener()                             │
│    212 │   else:                                                             │
│    213 │   │   opener = _opener                                              │
│ ❱  214 │   return opener.open(url, data, timeout)                            │
│    215                                                                       │
│    216 def install_opener(opener):                                           │
│    217 │   global _opener                                                    │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:51 │
│ 7 in open                                                                    │
│                                                                              │
│    514 │   │   │   req = meth(req)                                           │
│    515 │   │                                                                 │
│    516 │   │   sys.audit('urllib.Request', req.full_url, req.data, req.heade │
│ ❱  517 │   │   response = self._open(req, data)                              │
│    518 │   │                                                                 │
│    519 │   │   # post-process response                                       │
│    520 │   │   meth_name = protocol+"_response"                              │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:53 │
│ 4 in _open                                                                   │
│                                                                              │
│    531 │   │   │   return result                                             │
│    532 │   │                                                                 │
│    533 │   │   protocol = req.type                                           │
│ ❱  534 │   │   result = self._call_chain(self.handle_open, protocol, protoco │
│    535 │   │   │   │   │   │   │   │     '_open', req)                       │
│    536 │   │   if result:                                                    │
│    537 │   │   │   return result                                             │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:49 │
│ 4 in _call_chain                                                             │
│                                                                              │
│    491 │   │   handlers = chain.get(kind, ())                                │
│    492 │   │   for handler in handlers:                                      │
│    493 │   │   │   func = getattr(handler, meth_name)                        │
│ ❱  494 │   │   │   result = func(*args)                                      │
│    495 │   │   │   if result is not None:                                    │
│    496 │   │   │   │   return result                                         │
│    497                                                                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:13 │
│ 89 in https_open                                                             │
│                                                                              │
│   1386 │   │   │   self._check_hostname = check_hostname                     │
│   1387 │   │                                                                 │
│   1388 │   │   def https_open(self, req):                                    │
│ ❱ 1389 │   │   │   return self.do_open(http.client.HTTPSConnection, req,     │
│   1390 │   │   │   │   context=self._context, check_hostname=self._check_hos │
│   1391 │   │                                                                 │
│   1392 │   │   https_request = AbstractHTTPHandler.do_request_               │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:13 │
│ 49 in do_open                                                                │
│                                                                              │
│   1346 │   │   │   │   h.request(req.get_method(), req.selector, req.data, h │
│   1347 │   │   │   │   │   │     encode_chunked=req.has_header('Transfer-enc │
│   1348 │   │   │   except OSError as err: # timeout error                    │
│ ❱ 1349 │   │   │   │   raise URLError(err)                                   │
│   1350 │   │   │   r = h.getresponse()                                       │
│   1351 │   │   except:                                                       │
│   1352 │   │   │   h.close()                                                 │
╰──────────────────────────────────────────────────────────────────────────────╯
URLError: <urlopen error [Errno -2] Name or service not known>
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 16866 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 16867 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 16868 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 16865) of binary: /public/home/mswanghao/anaconda3/envs/LLM/bin/python
Traceback (most recent call last):
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 723, in <module>
    main()
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 719, in main
    run(args)
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 710, in run
    elastic_launch(
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-18_18:27:26
  host      : b06r1n01
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 16865)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
