WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
loss DRSL3 b=1e-05 start=0 end=10loss DRSL3 b=1e-05 start=0 end=10

loss DRSL3 b=1e-05 start=0 end=10
loss DRSL3 b=1e-05 start=0 end=10
| distributed init (rank 1, world 4): env://| distributed init (rank 2, world 4): env://| distributed init (rank 0, world 4): env://


| distributed init (rank 3, world 4): env://
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
2023-08-16 00:46:53,617 [INFO] 
=====  Running Parameters    =====
2023-08-16 00:46:53,618 [INFO] {
    "amp": true,
    "batch_size_eval": 2,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 0.0001,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1,
    "min_lr": 1e-05,
    "num_workers": 4,
    "output_dir": "output/BLIP2/DRSL3_0_10Pretrain_stage2",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "image_text_pretrain",
    "train_splits": [
        "train"
    ],
    "warmup_lr": 1e-06,
    "warmup_steps": 2000,
    "weight_decay": 0.05,
    "world_size": 4
}
2023-08-16 00:46:53,618 [INFO] 
======  Dataset Attributes  ======
2023-08-16 00:46:53,619 [INFO] 
======== coco_caption =======
2023-08-16 00:46:53,619 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip2_image_train"
        }
    }
}
2023-08-16 00:46:53,620 [INFO] 
======  Model Attributes  ======
2023-08-16 00:46:53,620 [INFO] {
    "arch": "blip2_opt",
    "drop_path_rate": 0,
    "finetuned": "",
    "freeze_vit": true,
    "image_size": 224,
    "load_finetuned": false,
    "load_pretrained": true,
    "model_type": "pretrain_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth",
    "prompt": "",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-08-16 00:46:53,622 [INFO] Building datasets...
2023-08-16 00:47:34,568 [INFO] freeze vision encoder
2023-08-16 00:50:58,005 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth
2023-08-16 00:50:58,064 [INFO] Start training
2023-08-16 00:51:14,891 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-08-16 00:51:14,897 [INFO] Loaded 566747 records for train split from the dataset.
2023-08-16 00:51:14,897 [INFO] Loaded 5000 records for val split from the dataset.
2023-08-16 00:51:14,898 [INFO] Loaded 5000 records for test split from the dataset.
2023-08-16 00:51:14,953 [INFO] number of trainable parameters: 107133696
2023-08-16 00:51:14,970 [INFO] Start training epoch 0, 8855 iters per inner epoch.
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
Train: data epoch: [0]  [   0/8855]  eta: 2 days, 12:09:40  lr: 0.000001  loss: 6.2864  time: 24.4585  data: 0.0000  max mem: 11496
2023-08-16 00:51:39,504 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [  50/8855]  eta: 10:51:51  lr: 0.000003  loss: 4.4722  time: 4.0137  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 100/8855]  eta: 10:15:35  lr: 0.000006  loss: 4.0691  time: 4.0130  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 150/8855]  eta: 9:59:36  lr: 0.000008  loss: 4.0889  time: 3.9469  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 200/8855]  eta: 9:51:05  lr: 0.000011  loss: 3.6359  time: 4.0046  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 250/8855]  eta: 9:44:21  lr: 0.000013  loss: 3.9758  time: 3.9857  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 300/8855]  eta: 9:39:20  lr: 0.000016  loss: 3.5153  time: 4.0073  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 350/8855]  eta: 9:34:04  lr: 0.000018  loss: 2.8373  time: 3.9599  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 400/8855]  eta: 9:29:33  lr: 0.000021  loss: 2.7058  time: 4.0027  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 450/8855]  eta: 9:25:25  lr: 0.000023  loss: 2.5783  time: 4.0105  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 500/8855]  eta: 9:21:05  lr: 0.000026  loss: 2.7794  time: 3.9503  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 550/8855]  eta: 9:16:52  lr: 0.000028  loss: 2.6773  time: 3.9479  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 600/8855]  eta: 9:13:04  lr: 0.000031  loss: 2.6787  time: 3.9960  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 650/8855]  eta: 9:09:37  lr: 0.000033  loss: 2.5211  time: 4.0113  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 700/8855]  eta: 9:05:59  lr: 0.000036  loss: 2.7833  time: 3.9914  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 750/8855]  eta: 9:02:24  lr: 0.000038  loss: 2.4623  time: 3.9721  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 800/8855]  eta: 8:58:56  lr: 0.000041  loss: 2.3526  time: 3.9903  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 850/8855]  eta: 8:55:28  lr: 0.000043  loss: 2.6694  time: 4.0161  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [ 900/8855]  eta: 8:52:10  lr: 0.000046  loss: 2.6191  time: 4.0318  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [ 950/8855]  eta: 8:48:41  lr: 0.000048  loss: 2.3542  time: 4.0088  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1000/8855]  eta: 8:45:11  lr: 0.000051  loss: 2.3670  time: 4.0032  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1050/8855]  eta: 8:41:33  lr: 0.000053  loss: 2.5031  time: 3.9786  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1100/8855]  eta: 8:38:04  lr: 0.000055  loss: 2.8570  time: 3.9562  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1150/8855]  eta: 8:34:31  lr: 0.000058  loss: 2.2521  time: 3.9738  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1200/8855]  eta: 8:31:18  lr: 0.000060  loss: 2.9305  time: 4.0581  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1250/8855]  eta: 8:27:53  lr: 0.000063  loss: 2.4151  time: 3.9831  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1300/8855]  eta: 8:24:31  lr: 0.000065  loss: 2.8676  time: 3.9563  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1350/8855]  eta: 8:21:08  lr: 0.000068  loss: 2.6524  time: 3.9835  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1400/8855]  eta: 8:17:42  lr: 0.000070  loss: 2.3084  time: 4.0007  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1450/8855]  eta: 8:14:16  lr: 0.000073  loss: 2.3718  time: 3.9674  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1500/8855]  eta: 8:10:52  lr: 0.000075  loss: 2.3533  time: 4.0246  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1550/8855]  eta: 8:07:28  lr: 0.000078  loss: 2.3101  time: 3.9993  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1600/8855]  eta: 8:04:24  lr: 0.000080  loss: 2.7974  time: 4.1286  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1650/8855]  eta: 8:01:45  lr: 0.000083  loss: 2.2925  time: 4.2250  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1700/8855]  eta: 7:59:06  lr: 0.000085  loss: 2.1318  time: 4.2436  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1750/8855]  eta: 7:56:23  lr: 0.000088  loss: 2.3041  time: 4.1345  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1800/8855]  eta: 7:53:35  lr: 0.000090  loss: 2.2315  time: 4.1712  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1850/8855]  eta: 7:50:54  lr: 0.000093  loss: 2.4480  time: 4.2060  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1900/8855]  eta: 7:48:01  lr: 0.000095  loss: 2.5070  time: 4.1869  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1950/8855]  eta: 7:45:09  lr: 0.000098  loss: 2.2883  time: 4.1879  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2000/8855]  eta: 7:42:10  lr: 0.000100  loss: 2.4331  time: 4.2474  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2050/8855]  eta: 7:39:06  lr: 0.000100  loss: 2.5959  time: 4.1148  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2100/8855]  eta: 7:36:10  lr: 0.000100  loss: 2.4107  time: 4.2061  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2150/8855]  eta: 7:33:10  lr: 0.000100  loss: 2.3198  time: 4.1888  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2200/8855]  eta: 7:30:11  lr: 0.000100  loss: 2.1494  time: 4.2445  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2250/8855]  eta: 7:27:04  lr: 0.000100  loss: 2.0189  time: 4.1948  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2300/8855]  eta: 7:23:58  lr: 0.000100  loss: 2.4430  time: 4.1796  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2350/8855]  eta: 7:20:57  lr: 0.000100  loss: 2.1730  time: 4.2416  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2400/8855]  eta: 7:17:58  lr: 0.000100  loss: 2.4695  time: 4.2981  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2450/8855]  eta: 7:14:57  lr: 0.000100  loss: 2.2006  time: 4.2183  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2500/8855]  eta: 7:11:46  lr: 0.000100  loss: 2.1989  time: 4.1909  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2550/8855]  eta: 7:08:43  lr: 0.000100  loss: 2.4927  time: 4.2570  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2600/8855]  eta: 7:05:37  lr: 0.000100  loss: 1.8531  time: 4.1838  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2650/8855]  eta: 7:02:29  lr: 0.000100  loss: 2.4962  time: 4.2762  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2700/8855]  eta: 6:59:19  lr: 0.000100  loss: 2.3349  time: 4.1912  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2750/8855]  eta: 6:56:08  lr: 0.000100  loss: 2.0657  time: 4.1705  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2800/8855]  eta: 6:53:00  lr: 0.000100  loss: 2.3966  time: 4.2465  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2850/8855]  eta: 6:49:46  lr: 0.000100  loss: 2.0759  time: 4.2136  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2900/8855]  eta: 6:46:33  lr: 0.000100  loss: 2.2725  time: 4.1947  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2950/8855]  eta: 6:43:22  lr: 0.000100  loss: 1.9465  time: 4.2335  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3000/8855]  eta: 6:39:52  lr: 0.000100  loss: 2.4465  time: 3.9614  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3050/8855]  eta: 6:36:16  lr: 0.000100  loss: 2.5415  time: 3.9871  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3100/8855]  eta: 6:32:42  lr: 0.000100  loss: 2.2748  time: 4.0057  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3150/8855]  eta: 6:29:09  lr: 0.000100  loss: 2.1332  time: 4.0023  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3200/8855]  eta: 6:25:33  lr: 0.000100  loss: 2.2529  time: 3.9840  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3250/8855]  eta: 6:22:01  lr: 0.000100  loss: 1.9937  time: 3.9930  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3300/8855]  eta: 6:18:28  lr: 0.000100  loss: 2.3909  time: 3.9871  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3350/8855]  eta: 6:14:57  lr: 0.000100  loss: 2.0666  time: 3.9444  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3400/8855]  eta: 6:11:25  lr: 0.000100  loss: 2.0036  time: 4.0116  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3450/8855]  eta: 6:07:56  lr: 0.000100  loss: 2.3601  time: 4.0319  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3500/8855]  eta: 6:04:24  lr: 0.000100  loss: 2.2043  time: 3.9784  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3550/8855]  eta: 6:00:57  lr: 0.000100  loss: 2.2645  time: 4.0108  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3600/8855]  eta: 5:57:25  lr: 0.000100  loss: 2.3099  time: 4.0030  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3650/8855]  eta: 5:53:54  lr: 0.000100  loss: 2.3942  time: 3.9600  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3700/8855]  eta: 5:50:24  lr: 0.000100  loss: 2.3864  time: 3.9782  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3750/8855]  eta: 5:46:55  lr: 0.000100  loss: 2.2813  time: 4.0093  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3800/8855]  eta: 5:43:26  lr: 0.000100  loss: 2.3998  time: 3.9912  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3850/8855]  eta: 5:39:56  lr: 0.000100  loss: 2.3460  time: 3.9829  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3900/8855]  eta: 5:36:29  lr: 0.000100  loss: 2.0334  time: 3.9978  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3950/8855]  eta: 5:33:00  lr: 0.000100  loss: 2.0826  time: 3.9885  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4000/8855]  eta: 5:29:32  lr: 0.000100  loss: 2.3672  time: 4.0107  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4050/8855]  eta: 5:26:02  lr: 0.000100  loss: 2.4995  time: 3.9885  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4100/8855]  eta: 5:22:38  lr: 0.000100  loss: 2.5477  time: 4.0530  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4150/8855]  eta: 5:19:10  lr: 0.000100  loss: 2.1779  time: 3.9928  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4200/8855]  eta: 5:15:41  lr: 0.000100  loss: 2.0625  time: 3.9801  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4250/8855]  eta: 5:12:15  lr: 0.000100  loss: 2.2113  time: 4.0356  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4300/8855]  eta: 5:08:47  lr: 0.000100  loss: 2.0539  time: 4.0086  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4350/8855]  eta: 5:05:20  lr: 0.000100  loss: 2.2074  time: 3.9965  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4400/8855]  eta: 5:01:53  lr: 0.000100  loss: 2.3054  time: 3.9402  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4450/8855]  eta: 4:58:28  lr: 0.000100  loss: 2.0313  time: 3.9974  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4500/8855]  eta: 4:55:01  lr: 0.000100  loss: 2.7056  time: 3.9678  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4550/8855]  eta: 4:51:33  lr: 0.000100  loss: 2.3326  time: 3.9423  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4600/8855]  eta: 4:48:06  lr: 0.000100  loss: 2.2227  time: 4.0256  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4650/8855]  eta: 4:44:40  lr: 0.000100  loss: 2.1595  time: 3.9847  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4700/8855]  eta: 4:41:15  lr: 0.000100  loss: 2.0736  time: 4.0228  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4750/8855]  eta: 4:37:50  lr: 0.000100  loss: 2.5083  time: 4.0239  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4800/8855]  eta: 4:34:25  lr: 0.000100  loss: 2.2536  time: 3.9996  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4850/8855]  eta: 4:31:00  lr: 0.000100  loss: 1.9579  time: 3.9999  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4900/8855]  eta: 4:27:34  lr: 0.000100  loss: 2.4366  time: 3.9928  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4950/8855]  eta: 4:24:09  lr: 0.000100  loss: 2.0687  time: 3.9876  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5000/8855]  eta: 4:20:43  lr: 0.000100  loss: 1.9905  time: 3.9789  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5050/8855]  eta: 4:17:18  lr: 0.000100  loss: 2.5039  time: 4.0110  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5100/8855]  eta: 4:13:53  lr: 0.000100  loss: 2.0741  time: 3.9794  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5150/8855]  eta: 4:10:29  lr: 0.000100  loss: 2.3933  time: 4.0318  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5200/8855]  eta: 4:07:04  lr: 0.000100  loss: 2.2090  time: 3.9630  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5250/8855]  eta: 4:03:40  lr: 0.000100  loss: 1.9772  time: 3.9383  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5300/8855]  eta: 4:00:16  lr: 0.000100  loss: 2.0560  time: 4.0666  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5350/8855]  eta: 3:56:52  lr: 0.000100  loss: 2.0617  time: 4.0429  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5400/8855]  eta: 3:53:28  lr: 0.000100  loss: 1.9991  time: 3.9795  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5450/8855]  eta: 3:50:02  lr: 0.000100  loss: 2.1662  time: 3.9447  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5500/8855]  eta: 3:46:38  lr: 0.000100  loss: 2.1160  time: 3.9732  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5550/8855]  eta: 3:43:14  lr: 0.000100  loss: 1.9397  time: 4.0028  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5600/8855]  eta: 3:39:50  lr: 0.000100  loss: 1.9182  time: 3.9620  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5650/8855]  eta: 3:36:25  lr: 0.000100  loss: 2.1110  time: 3.9716  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5700/8855]  eta: 3:33:01  lr: 0.000100  loss: 2.3715  time: 3.9650  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5750/8855]  eta: 3:29:37  lr: 0.000100  loss: 2.2688  time: 4.0518  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5800/8855]  eta: 3:26:13  lr: 0.000100  loss: 1.8646  time: 4.0306  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5850/8855]  eta: 3:22:49  lr: 0.000100  loss: 2.2765  time: 3.9755  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5900/8855]  eta: 3:19:26  lr: 0.000100  loss: 1.8211  time: 4.0299  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5950/8855]  eta: 3:16:03  lr: 0.000100  loss: 2.6427  time: 3.9918  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6000/8855]  eta: 3:12:40  lr: 0.000100  loss: 2.0461  time: 4.0349  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6050/8855]  eta: 3:09:17  lr: 0.000100  loss: 2.3725  time: 4.0643  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6100/8855]  eta: 3:05:53  lr: 0.000100  loss: 2.2328  time: 4.0193  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6150/8855]  eta: 3:02:30  lr: 0.000100  loss: 2.3783  time: 4.0191  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6200/8855]  eta: 2:59:07  lr: 0.000100  loss: 2.3436  time: 3.9887  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6250/8855]  eta: 2:55:44  lr: 0.000100  loss: 2.1708  time: 3.9939  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6300/8855]  eta: 2:52:22  lr: 0.000100  loss: 2.0714  time: 4.0840  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6350/8855]  eta: 2:48:58  lr: 0.000100  loss: 2.1981  time: 3.9919  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6400/8855]  eta: 2:45:36  lr: 0.000100  loss: 2.4033  time: 4.0273  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6450/8855]  eta: 2:42:14  lr: 0.000100  loss: 2.3267  time: 4.0279  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6500/8855]  eta: 2:38:51  lr: 0.000100  loss: 2.2614  time: 4.0401  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6550/8855]  eta: 2:35:28  lr: 0.000100  loss: 2.6418  time: 4.0735  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6600/8855]  eta: 2:32:05  lr: 0.000100  loss: 2.1114  time: 4.0351  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6650/8855]  eta: 2:28:42  lr: 0.000100  loss: 2.2309  time: 3.9928  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6700/8855]  eta: 2:25:20  lr: 0.000100  loss: 2.0609  time: 4.0411  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6750/8855]  eta: 2:21:57  lr: 0.000100  loss: 2.4955  time: 4.0758  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6800/8855]  eta: 2:18:35  lr: 0.000100  loss: 2.1251  time: 4.0185  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6850/8855]  eta: 2:15:12  lr: 0.000100  loss: 1.8944  time: 4.0262  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6900/8855]  eta: 2:11:49  lr: 0.000100  loss: 1.9838  time: 3.9865  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6950/8855]  eta: 2:08:27  lr: 0.000100  loss: 2.2907  time: 4.0194  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7000/8855]  eta: 2:05:04  lr: 0.000100  loss: 2.0236  time: 3.9754  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7050/8855]  eta: 2:01:42  lr: 0.000100  loss: 2.1439  time: 4.0391  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7100/8855]  eta: 1:58:19  lr: 0.000100  loss: 2.1108  time: 4.0204  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7150/8855]  eta: 1:54:56  lr: 0.000100  loss: 2.4471  time: 3.9825  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7200/8855]  eta: 1:51:33  lr: 0.000100  loss: 1.9974  time: 4.0026  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7250/8855]  eta: 1:48:11  lr: 0.000100  loss: 2.1000  time: 4.0232  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7300/8855]  eta: 1:44:48  lr: 0.000100  loss: 2.2393  time: 3.9846  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7350/8855]  eta: 1:41:26  lr: 0.000100  loss: 2.3681  time: 3.9726  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7400/8855]  eta: 1:38:03  lr: 0.000100  loss: 2.3323  time: 3.9944  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7450/8855]  eta: 1:34:41  lr: 0.000100  loss: 2.4054  time: 4.0005  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7500/8855]  eta: 1:31:19  lr: 0.000100  loss: 2.4253  time: 4.0313  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7550/8855]  eta: 1:27:56  lr: 0.000100  loss: 2.4241  time: 4.0589  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7600/8855]  eta: 1:24:35  lr: 0.000100  loss: 2.3778  time: 4.0556  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7650/8855]  eta: 1:21:12  lr: 0.000100  loss: 2.2051  time: 3.9903  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7700/8855]  eta: 1:17:49  lr: 0.000100  loss: 2.2834  time: 3.9701  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7750/8855]  eta: 1:14:27  lr: 0.000100  loss: 1.8892  time: 4.0614  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7800/8855]  eta: 1:11:05  lr: 0.000100  loss: 2.1959  time: 3.9764  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7850/8855]  eta: 1:07:42  lr: 0.000100  loss: 2.2011  time: 4.0075  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7900/8855]  eta: 1:04:20  lr: 0.000100  loss: 2.0030  time: 3.9908  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7950/8855]  eta: 1:00:58  lr: 0.000100  loss: 2.3758  time: 4.0011  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8000/8855]  eta: 0:57:36  lr: 0.000100  loss: 2.1386  time: 4.0501  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8050/8855]  eta: 0:54:13  lr: 0.000100  loss: 2.4136  time: 4.0394  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8100/8855]  eta: 0:50:51  lr: 0.000100  loss: 2.2839  time: 4.0248  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8150/8855]  eta: 0:47:29  lr: 0.000100  loss: 1.9050  time: 4.0331  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8200/8855]  eta: 0:44:07  lr: 0.000100  loss: 2.1836  time: 4.0296  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8250/8855]  eta: 0:40:45  lr: 0.000100  loss: 1.9810  time: 3.9763  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8300/8855]  eta: 0:37:23  lr: 0.000100  loss: 2.1029  time: 4.0383  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8350/8855]  eta: 0:34:00  lr: 0.000100  loss: 2.3858  time: 3.9939  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8400/8855]  eta: 0:30:38  lr: 0.000100  loss: 2.0403  time: 4.0829  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8450/8855]  eta: 0:27:16  lr: 0.000100  loss: 2.0211  time: 4.0342  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8500/8855]  eta: 0:23:54  lr: 0.000100  loss: 2.3246  time: 4.0629  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8550/8855]  eta: 0:20:32  lr: 0.000100  loss: 2.2774  time: 4.0482  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8600/8855]  eta: 0:17:10  lr: 0.000100  loss: 1.8893  time: 4.0673  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8650/8855]  eta: 0:13:48  lr: 0.000100  loss: 2.1842  time: 4.1025  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8700/8855]  eta: 0:10:26  lr: 0.000100  loss: 2.2435  time: 3.9747  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8750/8855]  eta: 0:07:04  lr: 0.000100  loss: 2.1160  time: 3.9941  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8800/8855]  eta: 0:03:42  lr: 0.000100  loss: 1.9473  time: 4.0129  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8850/8855]  eta: 0:00:20  lr: 0.000100  loss: 1.9693  time: 3.9824  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8854/8855]  eta: 0:00:04  lr: 0.000100  loss: 2.1036  time: 3.9964  data: 0.0000  max mem: 13620
Train: data epoch: [0] Total time: 9:56:16 (4.0403 s / it)
2023-08-16 10:47:31,685 [INFO] Averaged stats: lr: 0.0001  loss: 2.3459
2023-08-16 10:47:31,742 [INFO] No validation splits found.
2023-08-16 10:47:31,795 [INFO] Saving checkpoint at epoch 0 to /public/home/mswanghao/TorchProject/lavis/lavis/output/BLIP2/DRSL3_0_10Pretrain_stage2/20230816004/checkpoint_0.pth.
2023-08-16 10:47:36,676 [INFO] No validation splits found.
2023-08-16 10:47:36,708 [INFO] Training time 9:56:38
