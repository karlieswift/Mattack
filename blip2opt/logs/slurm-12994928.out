WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
loss DRSL3 b=1e-05 start=0 end=100loss DRSL3 b=1e-05 start=0 end=100

loss DRSL3 b=1e-05 start=0 end=100
loss DRSL3 b=1e-05 start=0 end=100
| distributed init (rank 3, world 4): env://| distributed init (rank 2, world 4): env://
| distributed init (rank 0, world 4): env://| distributed init (rank 1, world 4): env://


[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
2023-08-18 01:21:39,774 [INFO] 
=====  Running Parameters    =====
2023-08-18 01:21:39,775 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 2,
    "batch_size_train": 12,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1,
    "max_len": 30,
    "min_len": 8,
    "min_lr": 0,
    "num_beams": 5,
    "num_workers": 4,
    "output_dir": "output/BLIP2/Caption_coco_drsl_0_100",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "captioning",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "warmup_lr": 1e-08,
    "warmup_steps": 1000,
    "weight_decay": 0.05,
    "world_size": 4
}
2023-08-18 01:21:39,775 [INFO] 
======  Dataset Attributes  ======
2023-08-18 01:21:39,776 [INFO] 
======== coco_caption =======
2023-08-18 01:21:39,776 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a photo of "
        }
    },
    "vis_processor": {
        "eval": {
            "image_size": 364,
            "name": "blip_image_eval"
        },
        "train": {
            "image_size": 364,
            "name": "blip2_image_train"
        }
    }
}
2023-08-18 01:21:39,776 [INFO] 
======  Model Attributes  ======
2023-08-18 01:21:39,777 [INFO] {
    "arch": "blip2_opt",
    "drop_path_rate": 0,
    "freeze_vit": true,
    "image_size": 364,
    "load_finetuned": false,
    "model_type": "caption_coco_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth",
    "prompt": "a photo of",
    "use_grad_checkpoint": true,
    "vit_precision": "fp32"
}
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-08-18 01:21:39,788 [INFO] Building datasets...
BlipImageEvalProcessor
Position interpolate from 16x16 to 26x26
2023-08-18 01:22:18,443 [INFO] freeze vision encoder
2023-08-18 01:25:40,525 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth
2023-08-18 01:25:40,555 [INFO] Start training
2023-08-18 01:26:01,070 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-08-18 01:26:01,071 [INFO] Loaded 566747 records for train split from the dataset.
2023-08-18 01:26:01,071 [INFO] Loaded 5000 records for val split from the dataset.
2023-08-18 01:26:01,071 [INFO] Loaded 5000 records for test split from the dataset.
2023-08-18 01:26:01,151 [INFO] number of trainable parameters: 107133696
2023-08-18 01:26:01,152 [INFO] Start training epoch 0, 11807 iters per inner epoch.
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Train: data epoch: [0]  [    0/11807]  eta: 3 days, 9:27:21  lr: 0.000000  loss: 2.0363  time: 24.8362  data: 0.0000  max mem: 13105
2023-08-18 01:26:26,082 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [   50/11807]  eta: 17:38:00  lr: 0.000001  loss: 2.3918  time: 4.9967  data: 0.0000  max mem: 14868
Train: data epoch: [0]  [  100/11807]  eta: 17:32:09  lr: 0.000001  loss: 2.1082  time: 5.3977  data: 0.0000  max mem: 14868
Train: data epoch: [0]  [  150/11807]  eta: 17:20:36  lr: 0.000002  loss: 1.6545  time: 5.3080  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  200/11807]  eta: 17:14:29  lr: 0.000002  loss: 1.6314  time: 5.3848  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  250/11807]  eta: 17:08:45  lr: 0.000003  loss: 2.0286  time: 5.3014  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  300/11807]  eta: 17:02:26  lr: 0.000003  loss: 1.8270  time: 5.2755  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  350/11807]  eta: 16:56:40  lr: 0.000004  loss: 1.9611  time: 5.2760  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  400/11807]  eta: 16:51:08  lr: 0.000004  loss: 1.7821  time: 5.2454  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  450/11807]  eta: 16:45:35  lr: 0.000005  loss: 2.2213  time: 5.2773  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  500/11807]  eta: 16:40:27  lr: 0.000005  loss: 2.0239  time: 5.2252  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  550/11807]  eta: 16:35:41  lr: 0.000006  loss: 2.1088  time: 5.2789  data: 0.0000  max mem: 14892
Train: data epoch: [0]  [  600/11807]  eta: 16:31:03  lr: 0.000006  loss: 2.0416  time: 5.2933  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  650/11807]  eta: 16:26:26  lr: 0.000007  loss: 2.0891  time: 5.2373  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  700/11807]  eta: 16:21:30  lr: 0.000007  loss: 1.6906  time: 5.2938  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  750/11807]  eta: 16:16:57  lr: 0.000008  loss: 1.7071  time: 5.2875  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  800/11807]  eta: 16:12:29  lr: 0.000008  loss: 1.8161  time: 5.3297  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  850/11807]  eta: 16:07:43  lr: 0.000009  loss: 2.1500  time: 5.2486  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  900/11807]  eta: 16:03:07  lr: 0.000009  loss: 2.2549  time: 5.2760  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [  950/11807]  eta: 15:58:25  lr: 0.000010  loss: 2.0137  time: 5.2888  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1000/11807]  eta: 15:53:57  lr: 0.000010  loss: 2.3815  time: 5.2836  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1050/11807]  eta: 15:49:31  lr: 0.000010  loss: 2.0624  time: 5.2565  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1100/11807]  eta: 15:45:05  lr: 0.000010  loss: 1.9293  time: 5.2814  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1150/11807]  eta: 15:40:32  lr: 0.000010  loss: 2.0770  time: 5.2573  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1200/11807]  eta: 15:36:09  lr: 0.000010  loss: 2.0022  time: 5.3023  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1250/11807]  eta: 15:31:40  lr: 0.000010  loss: 1.6616  time: 5.3164  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1300/11807]  eta: 15:27:15  lr: 0.000010  loss: 2.3958  time: 5.2847  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1350/11807]  eta: 15:22:44  lr: 0.000010  loss: 1.6829  time: 5.2832  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1400/11807]  eta: 15:18:17  lr: 0.000010  loss: 2.0416  time: 5.2923  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1450/11807]  eta: 15:13:57  lr: 0.000010  loss: 1.8558  time: 5.2739  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1500/11807]  eta: 15:09:24  lr: 0.000010  loss: 1.9516  time: 5.2536  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1550/11807]  eta: 15:05:00  lr: 0.000010  loss: 2.0916  time: 5.3156  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1600/11807]  eta: 15:00:37  lr: 0.000010  loss: 2.6825  time: 5.2774  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1650/11807]  eta: 14:56:04  lr: 0.000010  loss: 2.1865  time: 5.2414  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1700/11807]  eta: 14:51:43  lr: 0.000010  loss: 2.4113  time: 5.3211  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1750/11807]  eta: 14:47:18  lr: 0.000010  loss: 2.1809  time: 5.2811  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1800/11807]  eta: 14:42:59  lr: 0.000010  loss: 2.3768  time: 5.3247  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1850/11807]  eta: 14:38:33  lr: 0.000010  loss: 1.8789  time: 5.3049  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1900/11807]  eta: 14:34:07  lr: 0.000010  loss: 1.8644  time: 5.2663  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 1950/11807]  eta: 14:29:40  lr: 0.000010  loss: 2.1845  time: 5.3003  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2000/11807]  eta: 14:25:19  lr: 0.000010  loss: 1.8772  time: 5.2953  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2050/11807]  eta: 14:20:50  lr: 0.000010  loss: 2.0196  time: 5.2754  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2100/11807]  eta: 14:16:23  lr: 0.000010  loss: 2.0302  time: 5.2768  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2150/11807]  eta: 14:11:52  lr: 0.000010  loss: 2.1581  time: 5.2502  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2200/11807]  eta: 14:07:27  lr: 0.000010  loss: 2.0645  time: 5.2839  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2250/11807]  eta: 14:03:03  lr: 0.000010  loss: 1.8165  time: 5.3257  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2300/11807]  eta: 13:58:39  lr: 0.000010  loss: 2.3471  time: 5.2886  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2350/11807]  eta: 13:54:13  lr: 0.000010  loss: 2.0788  time: 5.2588  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2400/11807]  eta: 13:49:48  lr: 0.000010  loss: 2.0923  time: 5.2822  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2450/11807]  eta: 13:45:18  lr: 0.000010  loss: 1.7891  time: 5.2684  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2500/11807]  eta: 13:40:53  lr: 0.000010  loss: 2.0162  time: 5.2646  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2550/11807]  eta: 13:36:34  lr: 0.000010  loss: 1.9891  time: 5.2807  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2600/11807]  eta: 13:32:04  lr: 0.000010  loss: 2.0732  time: 5.2622  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2650/11807]  eta: 13:27:42  lr: 0.000010  loss: 1.7750  time: 5.2956  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2700/11807]  eta: 13:23:16  lr: 0.000010  loss: 2.4979  time: 5.2737  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2750/11807]  eta: 13:18:55  lr: 0.000010  loss: 1.9084  time: 5.3212  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2800/11807]  eta: 13:14:27  lr: 0.000010  loss: 1.9733  time: 5.2931  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2850/11807]  eta: 13:10:00  lr: 0.000010  loss: 1.9897  time: 5.3021  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2900/11807]  eta: 13:05:36  lr: 0.000010  loss: 1.7481  time: 5.2849  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 2950/11807]  eta: 13:01:11  lr: 0.000010  loss: 2.0770  time: 5.2752  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3000/11807]  eta: 12:56:44  lr: 0.000010  loss: 1.7402  time: 5.2818  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3050/11807]  eta: 12:52:19  lr: 0.000010  loss: 2.0862  time: 5.2641  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3100/11807]  eta: 12:47:53  lr: 0.000010  loss: 2.2891  time: 5.3141  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3150/11807]  eta: 12:43:29  lr: 0.000010  loss: 1.9288  time: 5.2898  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3200/11807]  eta: 12:39:04  lr: 0.000010  loss: 2.2865  time: 5.2820  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3250/11807]  eta: 12:34:39  lr: 0.000010  loss: 2.4335  time: 5.3199  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3300/11807]  eta: 12:30:13  lr: 0.000010  loss: 2.0754  time: 5.2726  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3350/11807]  eta: 12:25:48  lr: 0.000010  loss: 1.9689  time: 5.3127  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3400/11807]  eta: 12:20:59  lr: 0.000010  loss: 2.4676  time: 5.0354  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3450/11807]  eta: 12:16:04  lr: 0.000010  loss: 2.2379  time: 5.0240  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3500/11807]  eta: 12:11:09  lr: 0.000010  loss: 2.1294  time: 5.0552  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3550/11807]  eta: 12:06:18  lr: 0.000010  loss: 2.0876  time: 5.0505  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3600/11807]  eta: 12:01:25  lr: 0.000010  loss: 2.0904  time: 5.0203  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3650/11807]  eta: 11:56:32  lr: 0.000010  loss: 1.9198  time: 5.0009  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3700/11807]  eta: 11:51:41  lr: 0.000010  loss: 1.9342  time: 5.0359  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3750/11807]  eta: 11:46:51  lr: 0.000010  loss: 2.5357  time: 5.0362  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3800/11807]  eta: 11:42:01  lr: 0.000010  loss: 1.8471  time: 5.0096  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3850/11807]  eta: 11:37:15  lr: 0.000010  loss: 2.1060  time: 5.0195  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3900/11807]  eta: 11:32:30  lr: 0.000010  loss: 1.7119  time: 5.0476  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 3950/11807]  eta: 11:27:43  lr: 0.000010  loss: 2.0398  time: 4.9878  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4000/11807]  eta: 11:22:58  lr: 0.000010  loss: 2.1176  time: 5.0335  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4050/11807]  eta: 11:18:13  lr: 0.000010  loss: 2.1374  time: 5.0275  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4100/11807]  eta: 11:13:30  lr: 0.000010  loss: 1.9019  time: 5.0422  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4150/11807]  eta: 11:08:46  lr: 0.000010  loss: 2.1958  time: 5.0078  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4200/11807]  eta: 11:04:02  lr: 0.000010  loss: 2.0064  time: 5.0045  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4250/11807]  eta: 10:59:22  lr: 0.000010  loss: 2.0089  time: 5.0449  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4300/11807]  eta: 10:54:42  lr: 0.000010  loss: 2.4004  time: 5.0305  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4350/11807]  eta: 10:50:03  lr: 0.000010  loss: 2.2336  time: 5.0401  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4400/11807]  eta: 10:45:22  lr: 0.000010  loss: 2.2438  time: 5.0149  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4450/11807]  eta: 10:40:44  lr: 0.000010  loss: 2.0263  time: 5.0150  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4500/11807]  eta: 10:36:04  lr: 0.000010  loss: 2.0800  time: 5.0254  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4550/11807]  eta: 10:31:28  lr: 0.000010  loss: 2.2862  time: 5.0721  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4600/11807]  eta: 10:26:53  lr: 0.000010  loss: 2.3178  time: 5.0131  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4650/11807]  eta: 10:22:20  lr: 0.000010  loss: 2.0676  time: 5.0233  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4700/11807]  eta: 10:17:45  lr: 0.000010  loss: 2.1889  time: 5.0230  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4750/11807]  eta: 10:13:09  lr: 0.000010  loss: 2.3246  time: 4.9922  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4800/11807]  eta: 10:08:34  lr: 0.000010  loss: 2.1402  time: 5.0264  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4850/11807]  eta: 10:04:01  lr: 0.000010  loss: 1.8845  time: 5.0242  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4900/11807]  eta: 9:59:28  lr: 0.000010  loss: 2.2743  time: 5.0247  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 4950/11807]  eta: 9:54:54  lr: 0.000010  loss: 2.1402  time: 4.9977  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5000/11807]  eta: 9:50:22  lr: 0.000010  loss: 2.3681  time: 5.0530  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5050/11807]  eta: 9:45:49  lr: 0.000010  loss: 1.7827  time: 5.0090  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5100/11807]  eta: 9:41:19  lr: 0.000010  loss: 2.2875  time: 5.0519  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5150/11807]  eta: 9:36:48  lr: 0.000010  loss: 1.9144  time: 5.0557  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5200/11807]  eta: 9:32:17  lr: 0.000010  loss: 1.7786  time: 5.0413  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5250/11807]  eta: 9:27:46  lr: 0.000010  loss: 1.9657  time: 4.9950  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5300/11807]  eta: 9:23:15  lr: 0.000010  loss: 2.4835  time: 5.0355  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5350/11807]  eta: 9:18:45  lr: 0.000010  loss: 1.8725  time: 5.0190  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5400/11807]  eta: 9:14:13  lr: 0.000010  loss: 2.4334  time: 5.0080  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5450/11807]  eta: 9:09:45  lr: 0.000010  loss: 2.3223  time: 5.0192  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5500/11807]  eta: 9:05:16  lr: 0.000010  loss: 2.1392  time: 5.0361  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5550/11807]  eta: 9:00:47  lr: 0.000010  loss: 2.5627  time: 5.0120  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5600/11807]  eta: 8:56:19  lr: 0.000010  loss: 1.9305  time: 5.0473  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5650/11807]  eta: 8:51:52  lr: 0.000010  loss: 1.7026  time: 5.0465  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5700/11807]  eta: 8:47:25  lr: 0.000010  loss: 2.1674  time: 5.0011  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5750/11807]  eta: 8:42:58  lr: 0.000010  loss: 2.2093  time: 5.0263  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5800/11807]  eta: 8:38:31  lr: 0.000010  loss: 2.0898  time: 5.0168  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5850/11807]  eta: 8:34:05  lr: 0.000010  loss: 1.9764  time: 5.0094  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5900/11807]  eta: 8:29:37  lr: 0.000010  loss: 2.3935  time: 5.0094  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 5950/11807]  eta: 8:25:12  lr: 0.000010  loss: 2.0756  time: 5.0669  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6000/11807]  eta: 8:20:46  lr: 0.000010  loss: 2.5103  time: 5.0467  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6050/11807]  eta: 8:16:21  lr: 0.000010  loss: 2.3557  time: 5.0259  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6100/11807]  eta: 8:11:55  lr: 0.000010  loss: 2.4032  time: 5.0234  data: 0.0000  max mem: 14906
Train: data epoch: [0]  [ 6150/11807]  eta: 8:07:28  lr: 0.000010  loss: 2.0964  time: 4.9815  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6200/11807]  eta: 8:03:03  lr: 0.000010  loss: 1.9591  time: 5.0325  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6250/11807]  eta: 7:58:39  lr: 0.000010  loss: 1.7995  time: 5.0490  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6300/11807]  eta: 7:54:15  lr: 0.000010  loss: 1.5907  time: 5.0469  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6350/11807]  eta: 7:49:51  lr: 0.000010  loss: 2.1679  time: 5.0891  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6400/11807]  eta: 7:45:26  lr: 0.000010  loss: 2.3876  time: 5.0064  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6450/11807]  eta: 7:41:03  lr: 0.000010  loss: 2.2392  time: 5.0483  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6500/11807]  eta: 7:36:40  lr: 0.000010  loss: 2.0089  time: 5.0418  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6550/11807]  eta: 7:32:16  lr: 0.000010  loss: 1.7809  time: 5.0120  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6600/11807]  eta: 7:27:52  lr: 0.000010  loss: 1.6089  time: 5.0226  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6650/11807]  eta: 7:23:28  lr: 0.000010  loss: 2.0434  time: 5.0077  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6700/11807]  eta: 7:19:04  lr: 0.000010  loss: 2.3235  time: 5.0225  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6750/11807]  eta: 7:14:41  lr: 0.000010  loss: 2.0290  time: 4.9894  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6800/11807]  eta: 7:10:18  lr: 0.000010  loss: 2.0754  time: 5.0140  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6850/11807]  eta: 7:05:55  lr: 0.000010  loss: 2.2766  time: 5.0056  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6900/11807]  eta: 7:01:33  lr: 0.000010  loss: 1.9341  time: 5.0063  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 6950/11807]  eta: 6:57:11  lr: 0.000010  loss: 1.9370  time: 5.0279  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7000/11807]  eta: 6:52:49  lr: 0.000010  loss: 1.9021  time: 5.0335  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7050/11807]  eta: 6:48:27  lr: 0.000010  loss: 1.8310  time: 5.0423  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7100/11807]  eta: 6:44:05  lr: 0.000010  loss: 1.8299  time: 5.0271  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7150/11807]  eta: 6:39:43  lr: 0.000010  loss: 2.1982  time: 5.0160  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7200/11807]  eta: 6:35:21  lr: 0.000010  loss: 1.7123  time: 5.0041  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7250/11807]  eta: 6:31:00  lr: 0.000010  loss: 1.9324  time: 5.0238  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7300/11807]  eta: 6:26:39  lr: 0.000010  loss: 2.0080  time: 5.0422  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7350/11807]  eta: 6:22:18  lr: 0.000010  loss: 1.8318  time: 5.0386  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7400/11807]  eta: 6:17:57  lr: 0.000010  loss: 1.8616  time: 5.0257  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7450/11807]  eta: 6:13:37  lr: 0.000010  loss: 2.0944  time: 5.0128  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7500/11807]  eta: 6:09:15  lr: 0.000010  loss: 2.1457  time: 5.0302  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7550/11807]  eta: 6:04:54  lr: 0.000010  loss: 1.9771  time: 5.0297  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7600/11807]  eta: 6:00:34  lr: 0.000010  loss: 2.3860  time: 5.0493  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7650/11807]  eta: 5:56:13  lr: 0.000010  loss: 2.3125  time: 5.0061  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7700/11807]  eta: 5:51:53  lr: 0.000010  loss: 1.7738  time: 5.0112  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7750/11807]  eta: 5:47:33  lr: 0.000010  loss: 2.2926  time: 5.0296  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7800/11807]  eta: 5:43:13  lr: 0.000010  loss: 2.1200  time: 4.9955  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7850/11807]  eta: 5:38:53  lr: 0.000010  loss: 1.8644  time: 5.0419  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7900/11807]  eta: 5:34:33  lr: 0.000010  loss: 2.4151  time: 4.9946  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 7950/11807]  eta: 5:30:13  lr: 0.000010  loss: 2.4116  time: 5.0217  data: 0.0010  max mem: 14911
Train: data epoch: [0]  [ 8000/11807]  eta: 5:25:54  lr: 0.000010  loss: 2.2651  time: 5.0169  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8050/11807]  eta: 5:21:34  lr: 0.000010  loss: 2.4706  time: 5.0159  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8100/11807]  eta: 5:17:16  lr: 0.000010  loss: 1.6691  time: 5.0695  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8150/11807]  eta: 5:12:56  lr: 0.000010  loss: 2.4057  time: 4.9846  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8200/11807]  eta: 5:08:36  lr: 0.000010  loss: 2.3338  time: 5.0073  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8250/11807]  eta: 5:04:17  lr: 0.000010  loss: 2.3057  time: 5.0163  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8300/11807]  eta: 4:59:58  lr: 0.000010  loss: 2.0258  time: 5.0254  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8350/11807]  eta: 4:55:39  lr: 0.000010  loss: 2.1817  time: 5.0081  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8400/11807]  eta: 4:51:20  lr: 0.000010  loss: 2.0816  time: 4.9949  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8450/11807]  eta: 4:47:01  lr: 0.000010  loss: 2.4864  time: 4.9961  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8500/11807]  eta: 4:42:43  lr: 0.000010  loss: 1.8332  time: 5.0583  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8550/11807]  eta: 4:38:25  lr: 0.000010  loss: 2.3999  time: 5.0170  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8600/11807]  eta: 4:34:06  lr: 0.000010  loss: 2.0937  time: 5.0194  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8650/11807]  eta: 4:29:48  lr: 0.000010  loss: 2.3519  time: 5.0601  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8700/11807]  eta: 4:25:30  lr: 0.000010  loss: 2.2985  time: 5.0220  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8750/11807]  eta: 4:21:12  lr: 0.000010  loss: 2.1679  time: 5.0652  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8800/11807]  eta: 4:16:54  lr: 0.000010  loss: 2.1254  time: 5.0239  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8850/11807]  eta: 4:12:36  lr: 0.000010  loss: 1.7229  time: 5.0475  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8900/11807]  eta: 4:08:18  lr: 0.000010  loss: 1.8801  time: 5.0553  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 8950/11807]  eta: 4:04:01  lr: 0.000010  loss: 2.0289  time: 5.0295  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9000/11807]  eta: 3:59:43  lr: 0.000010  loss: 2.4033  time: 5.0176  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9050/11807]  eta: 3:55:25  lr: 0.000010  loss: 2.1570  time: 5.0265  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9100/11807]  eta: 3:51:07  lr: 0.000010  loss: 2.1263  time: 5.0074  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9150/11807]  eta: 3:46:50  lr: 0.000010  loss: 2.0468  time: 5.0340  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9200/11807]  eta: 3:42:32  lr: 0.000010  loss: 1.6979  time: 4.9649  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9250/11807]  eta: 3:38:15  lr: 0.000010  loss: 2.2953  time: 5.0168  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9300/11807]  eta: 3:33:57  lr: 0.000010  loss: 1.8892  time: 5.0171  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9350/11807]  eta: 3:29:40  lr: 0.000010  loss: 2.0333  time: 5.0415  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9400/11807]  eta: 3:25:23  lr: 0.000010  loss: 2.1149  time: 5.0327  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9450/11807]  eta: 3:21:06  lr: 0.000010  loss: 1.9997  time: 5.0344  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9500/11807]  eta: 3:16:48  lr: 0.000010  loss: 2.4210  time: 5.0105  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9550/11807]  eta: 3:12:31  lr: 0.000010  loss: 2.1159  time: 5.0204  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9600/11807]  eta: 3:08:14  lr: 0.000010  loss: 1.8713  time: 4.9875  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9650/11807]  eta: 3:03:57  lr: 0.000010  loss: 1.8378  time: 5.0305  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9700/11807]  eta: 2:59:40  lr: 0.000010  loss: 1.8137  time: 5.0185  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9750/11807]  eta: 2:55:23  lr: 0.000010  loss: 2.4664  time: 5.0043  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9800/11807]  eta: 2:51:06  lr: 0.000010  loss: 2.2527  time: 4.9922  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9850/11807]  eta: 2:46:50  lr: 0.000010  loss: 2.2996  time: 5.0081  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9900/11807]  eta: 2:42:33  lr: 0.000010  loss: 2.1063  time: 5.0319  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [ 9950/11807]  eta: 2:38:16  lr: 0.000010  loss: 1.9643  time: 5.0350  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10000/11807]  eta: 2:34:00  lr: 0.000010  loss: 2.2450  time: 5.0751  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10050/11807]  eta: 2:29:43  lr: 0.000010  loss: 1.9200  time: 5.0333  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10100/11807]  eta: 2:25:27  lr: 0.000010  loss: 2.0479  time: 5.0207  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10150/11807]  eta: 2:21:11  lr: 0.000010  loss: 2.2317  time: 5.0372  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10200/11807]  eta: 2:16:54  lr: 0.000010  loss: 1.7806  time: 5.0249  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10250/11807]  eta: 2:12:38  lr: 0.000010  loss: 2.1681  time: 4.9872  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10300/11807]  eta: 2:08:22  lr: 0.000010  loss: 2.3112  time: 4.9970  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10350/11807]  eta: 2:04:06  lr: 0.000010  loss: 2.1316  time: 5.0338  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10400/11807]  eta: 1:59:50  lr: 0.000010  loss: 2.2865  time: 5.0168  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10450/11807]  eta: 1:55:34  lr: 0.000010  loss: 1.8139  time: 5.0389  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10500/11807]  eta: 1:51:18  lr: 0.000010  loss: 1.8961  time: 5.0283  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10550/11807]  eta: 1:47:02  lr: 0.000010  loss: 2.5216  time: 5.0374  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10600/11807]  eta: 1:42:46  lr: 0.000010  loss: 2.3413  time: 5.0516  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10650/11807]  eta: 1:38:30  lr: 0.000010  loss: 2.0856  time: 5.0340  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10700/11807]  eta: 1:34:14  lr: 0.000010  loss: 2.2500  time: 5.0300  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10750/11807]  eta: 1:29:58  lr: 0.000010  loss: 1.9443  time: 4.9994  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10800/11807]  eta: 1:25:42  lr: 0.000010  loss: 2.0961  time: 4.9932  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10850/11807]  eta: 1:21:27  lr: 0.000010  loss: 2.3651  time: 5.0180  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10900/11807]  eta: 1:17:11  lr: 0.000010  loss: 2.2345  time: 5.0295  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [10950/11807]  eta: 1:12:55  lr: 0.000010  loss: 1.8963  time: 5.0299  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11000/11807]  eta: 1:08:40  lr: 0.000010  loss: 1.8372  time: 5.0416  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11050/11807]  eta: 1:04:24  lr: 0.000010  loss: 2.8250  time: 5.0356  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11100/11807]  eta: 1:00:09  lr: 0.000010  loss: 2.2613  time: 5.0284  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11150/11807]  eta: 0:55:53  lr: 0.000010  loss: 2.1370  time: 5.0518  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11200/11807]  eta: 0:51:38  lr: 0.000010  loss: 2.0840  time: 4.9971  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11250/11807]  eta: 0:47:22  lr: 0.000010  loss: 2.1312  time: 5.0145  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11300/11807]  eta: 0:43:07  lr: 0.000010  loss: 2.0077  time: 5.0311  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11350/11807]  eta: 0:38:52  lr: 0.000010  loss: 2.2658  time: 5.0365  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11400/11807]  eta: 0:34:36  lr: 0.000010  loss: 2.4574  time: 5.0023  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11450/11807]  eta: 0:30:21  lr: 0.000010  loss: 2.2047  time: 5.0064  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11500/11807]  eta: 0:26:06  lr: 0.000010  loss: 2.4618  time: 5.0145  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11550/11807]  eta: 0:21:51  lr: 0.000010  loss: 2.3083  time: 5.0796  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11600/11807]  eta: 0:17:36  lr: 0.000010  loss: 1.9908  time: 5.0618  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11650/11807]  eta: 0:13:20  lr: 0.000010  loss: 1.7801  time: 5.0487  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11700/11807]  eta: 0:09:05  lr: 0.000010  loss: 2.3295  time: 5.0369  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11750/11807]  eta: 0:04:50  lr: 0.000010  loss: 1.5320  time: 5.0040  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11800/11807]  eta: 0:00:35  lr: 0.000010  loss: 1.8881  time: 4.9909  data: 0.0000  max mem: 14911
Train: data epoch: [0]  [11806/11807]  eta: 0:00:05  lr: 0.000010  loss: 1.8931  time: 4.9954  data: 0.0000  max mem: 14911
Train: data epoch: [0] Total time: 16:43:38 (5.1002 s / it)
2023-08-18 18:09:39,834 [INFO] Averaged stats: lr: 0.0000  loss: 2.1042
2023-08-18 18:09:39,887 [INFO] Evaluating on val.
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
Evaluation  [  0/625]  eta: 1:10:20    time: 6.7520  data: 0.5807  max mem: 14911
Evaluation  [ 10/625]  eta: 0:44:12    time: 4.3136  data: 0.0536  max mem: 14911
Evaluation  [ 20/625]  eta: 0:41:35    time: 3.9929  data: 0.0008  max mem: 14911
Evaluation  [ 30/625]  eta: 0:40:50    time: 4.0118  data: 0.0007  max mem: 14911
Evaluation  [ 40/625]  eta: 0:39:58    time: 4.0755  data: 0.0007  max mem: 14911
Evaluation  [ 50/625]  eta: 0:40:10    time: 4.3044  data: 0.0007  max mem: 14911
Evaluation  [ 60/625]  eta: 0:39:33    time: 4.4046  data: 0.0009  max mem: 14911
Evaluation  [ 70/625]  eta: 0:39:14    time: 4.3692  data: 0.0008  max mem: 14911
Evaluation  [ 80/625]  eta: 0:38:00    time: 4.1326  data: 0.0008  max mem: 14911
Evaluation  [ 90/625]  eta: 0:37:23    time: 4.0247  data: 0.0009  max mem: 14911
Evaluation  [100/625]  eta: 0:36:29    time: 4.1194  data: 0.0008  max mem: 14911
Evaluation  [110/625]  eta: 0:35:44    time: 4.0309  data: 0.0007  max mem: 14911
Evaluation  [120/625]  eta: 0:35:04    time: 4.1536  data: 0.0008  max mem: 14911
Evaluation  [130/625]  eta: 0:34:26    time: 4.2296  data: 0.0009  max mem: 14911
Evaluation  [140/625]  eta: 0:33:43    time: 4.1917  data: 0.0008  max mem: 14911
Evaluation  [150/625]  eta: 0:33:02    time: 4.1743  data: 0.0009  max mem: 14911
Evaluation  [160/625]  eta: 0:32:20    time: 4.1825  data: 0.0008  max mem: 14911
Evaluation  [170/625]  eta: 0:31:33    time: 4.0671  data: 0.0008  max mem: 14911
Evaluation  [180/625]  eta: 0:30:55    time: 4.1441  data: 0.0019  max mem: 14911
Evaluation  [190/625]  eta: 0:30:23    time: 4.4501  data: 0.0020  max mem: 14911
Evaluation  [200/625]  eta: 0:29:42    time: 4.4112  data: 0.0010  max mem: 14911
Evaluation  [210/625]  eta: 0:29:03    time: 4.2921  data: 0.0008  max mem: 14911
Evaluation  [220/625]  eta: 0:28:20    time: 4.2534  data: 0.0014  max mem: 14911
Evaluation  [230/625]  eta: 0:27:40    time: 4.2135  data: 0.0018  max mem: 14911
Evaluation  [240/625]  eta: 0:26:59    time: 4.2941  data: 0.0011  max mem: 14911
Evaluation  [250/625]  eta: 0:26:16    time: 4.2328  data: 0.0007  max mem: 14911
Evaluation  [260/625]  eta: 0:25:32    time: 4.0889  data: 0.0007  max mem: 14911
Evaluation  [270/625]  eta: 0:24:48    time: 4.0548  data: 0.0007  max mem: 14911
Evaluation  [280/625]  eta: 0:24:10    time: 4.2862  data: 0.0008  max mem: 14911
Evaluation  [290/625]  eta: 0:23:35    time: 4.6327  data: 0.0009  max mem: 14911
Evaluation  [300/625]  eta: 0:22:52    time: 4.4768  data: 0.0009  max mem: 14911
Evaluation  [310/625]  eta: 0:22:08    time: 4.1256  data: 0.0008  max mem: 14911
Evaluation  [320/625]  eta: 0:21:27    time: 4.2195  data: 0.0009  max mem: 14911
Evaluation  [330/625]  eta: 0:20:43    time: 4.1583  data: 0.0008  max mem: 14911
Evaluation  [340/625]  eta: 0:20:02    time: 4.2040  data: 0.0010  max mem: 14911
Evaluation  [350/625]  eta: 0:19:22    time: 4.4733  data: 0.0011  max mem: 14911
Evaluation  [360/625]  eta: 0:18:42    time: 4.5092  data: 0.0008  max mem: 14911
Evaluation  [370/625]  eta: 0:17:59    time: 4.3383  data: 0.0008  max mem: 14911
Evaluation  [380/625]  eta: 0:17:16    time: 4.1540  data: 0.0008  max mem: 14911
Evaluation  [390/625]  eta: 0:16:32    time: 3.9994  data: 0.0008  max mem: 14911
Evaluation  [400/625]  eta: 0:15:48    time: 3.8618  data: 0.0008  max mem: 14911
Evaluation  [410/625]  eta: 0:15:05    time: 3.9800  data: 0.0009  max mem: 14911
Evaluation  [420/625]  eta: 0:14:21    time: 4.0158  data: 0.0011  max mem: 14911
Evaluation  [430/625]  eta: 0:13:40    time: 4.0979  data: 0.0011  max mem: 14911
Evaluation  [440/625]  eta: 0:12:56    time: 4.0430  data: 0.0008  max mem: 14911
Evaluation  [450/625]  eta: 0:12:13    time: 3.8563  data: 0.0008  max mem: 14911
Evaluation  [460/625]  eta: 0:11:31    time: 3.9925  data: 0.0008  max mem: 14911
Evaluation  [470/625]  eta: 0:10:49    time: 4.1577  data: 0.0007  max mem: 14911
Evaluation  [480/625]  eta: 0:10:06    time: 4.0394  data: 0.0007  max mem: 14911
Evaluation  [490/625]  eta: 0:09:24    time: 4.0105  data: 0.0008  max mem: 14911
Evaluation  [500/625]  eta: 0:08:42    time: 4.1538  data: 0.0008  max mem: 14911
Evaluation  [510/625]  eta: 0:08:00    time: 4.1412  data: 0.0007  max mem: 14911
Evaluation  [520/625]  eta: 0:07:17    time: 3.9172  data: 0.0007  max mem: 14911
Evaluation  [530/625]  eta: 0:06:36    time: 3.9096  data: 0.0008  max mem: 14911
Evaluation  [540/625]  eta: 0:05:54    time: 4.0727  data: 0.0007  max mem: 14911
Evaluation  [550/625]  eta: 0:05:12    time: 4.1999  data: 0.0008  max mem: 14911
Evaluation  [560/625]  eta: 0:04:31    time: 4.2403  data: 0.0008  max mem: 14911
Evaluation  [570/625]  eta: 0:03:49    time: 4.3175  data: 0.0008  max mem: 14911
Evaluation  [580/625]  eta: 0:03:07    time: 4.3937  data: 0.0011  max mem: 14911
Evaluation  [590/625]  eta: 0:02:26    time: 4.1540  data: 0.0010  max mem: 14911
Evaluation  [600/625]  eta: 0:01:44    time: 4.0793  data: 0.0007  max mem: 14911
Evaluation  [610/625]  eta: 0:01:02    time: 4.2398  data: 0.0007  max mem: 14911
Evaluation  [620/625]  eta: 0:00:20    time: 4.3387  data: 0.0007  max mem: 14911
Evaluation  [624/625]  eta: 0:00:04    time: 4.2897  data: 0.0027  max mem: 14911
Evaluation Total time: 0:43:31 (4.1779 s / it)
2023-08-18 18:54:04,694 [WARNING] rank 0 starts merging results.
result file saved to /public/home/mswanghao/TorchProject/lavis/lavis/output/BLIP2/Caption_coco_drsl_0_100/20230818012/result/val_epoch0.json
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:13 │
│ 46 in do_open                                                                │
│                                                                              │
│   1343 │   │                                                                 │
│   1344 │   │   try:                                                          │
│   1345 │   │   │   try:                                                      │
│ ❱ 1346 │   │   │   │   h.request(req.get_method(), req.selector, req.data, h │
│   1347 │   │   │   │   │   │     encode_chunked=req.has_header('Transfer-enc │
│   1348 │   │   │   except OSError as err: # timeout error                    │
│   1349 │   │   │   │   raise URLError(err)                                   │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1285  │
│ in request                                                                   │
│                                                                              │
│   1282 │   def request(self, method, url, body=None, headers={}, *,          │
│   1283 │   │   │   │   encode_chunked=False):                                │
│   1284 │   │   """Send a complete request to the server."""                  │
│ ❱ 1285 │   │   self._send_request(method, url, body, headers, encode_chunked │
│   1286 │                                                                     │
│   1287 │   def _send_request(self, method, url, body, headers, encode_chunke │
│   1288 │   │   # Honor explicitly requested Host: and Accept-Encoding: heade │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1331  │
│ in _send_request                                                             │
│                                                                              │
│   1328 │   │   │   # RFC 2616 Section 3.7.1 says that text default has a     │
│   1329 │   │   │   # default charset of iso-8859-1.                          │
│   1330 │   │   │   body = _encode(body, 'body')                              │
│ ❱ 1331 │   │   self.endheaders(body, encode_chunked=encode_chunked)          │
│   1332 │                                                                     │
│   1333 │   def getresponse(self):                                            │
│   1334 │   │   """Get the response from the server.                          │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1280  │
│ in endheaders                                                                │
│                                                                              │
│   1277 │   │   │   self.__state = _CS_REQ_SENT                               │
│   1278 │   │   else:                                                         │
│   1279 │   │   │   raise CannotSendHeader()                                  │
│ ❱ 1280 │   │   self._send_output(message_body, encode_chunked=encode_chunked │
│   1281 │                                                                     │
│   1282 │   def request(self, method, url, body=None, headers={}, *,          │
│   1283 │   │   │   │   encode_chunked=False):                                │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1040  │
│ in _send_output                                                              │
│                                                                              │
│   1037 │   │   self._buffer.extend((b"", b""))                               │
│   1038 │   │   msg = b"\r\n".join(self._buffer)                              │
│   1039 │   │   del self._buffer[:]                                           │
│ ❱ 1040 │   │   self.send(msg)                                                │
│   1041 │   │                                                                 │
│   1042 │   │   if message_body is not None:                                  │
│   1043                                                                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:980   │
│ in send                                                                      │
│                                                                              │
│    977 │   │                                                                 │
│    978 │   │   if self.sock is None:                                         │
│    979 │   │   │   if self.auto_open:                                        │
│ ❱  980 │   │   │   │   self.connect()                                        │
│    981 │   │   │   else:                                                     │
│    982 │   │   │   │   raise NotConnected()                                  │
│    983                                                                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:1447  │
│ in connect                                                                   │
│                                                                              │
│   1444 │   │   def connect(self):                                            │
│   1445 │   │   │   "Connect to a host on a given (SSL) port."                │
│   1446 │   │   │                                                             │
│ ❱ 1447 │   │   │   super().connect()                                         │
│   1448 │   │   │                                                             │
│   1449 │   │   │   if self._tunnel_host:                                     │
│   1450 │   │   │   │   server_hostname = self._tunnel_host                   │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/http/client.py:946   │
│ in connect                                                                   │
│                                                                              │
│    943 │                                                                     │
│    944 │   def connect(self):                                                │
│    945 │   │   """Connect to the host and port specified in __init__."""     │
│ ❱  946 │   │   self.sock = self._create_connection(                          │
│    947 │   │   │   (self.host,self.port), self.timeout, self.source_address) │
│    948 │   │   # Might fail in OSs that don't implement TCP_NODELAY          │
│    949 │   │   try:                                                          │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/socket.py:823 in     │
│ create_connection                                                            │
│                                                                              │
│   820 │                                                                      │
│   821 │   host, port = address                                               │
│   822 │   err = None                                                         │
│ ❱ 823 │   for res in getaddrinfo(host, port, 0, SOCK_STREAM):                │
│   824 │   │   af, socktype, proto, canonname, sa = res                       │
│   825 │   │   sock = None                                                    │
│   826 │   │   try:                                                           │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/socket.py:954 in     │
│ getaddrinfo                                                                  │
│                                                                              │
│   951 │   # We override this function since we want to translate the numeric │
│   952 │   # and socket type values to enum constants.                        │
│   953 │   addrlist = []                                                      │
│ ❱ 954 │   for res in _socket.getaddrinfo(host, port, family, type, proto, fl │
│   955 │   │   af, socktype, proto, canonname, sa = res                       │
│   956 │   │   addrlist.append((_intenum_converter(af, AddressFamily),        │
│   957 │   │   │   │   │   │    _intenum_converter(socktype, SocketKind),     │
╰──────────────────────────────────────────────────────────────────────────────╯
gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /public/home/mswanghao/TorchProject/lavis/train.py:116 in <module>           │
│                                                                              │
│   113                                                                        │
│   114                                                                        │
│   115 if __name__ == "__main__":                                             │
│ ❱ 116 │   main()                                                             │
│   117                                                                        │
│   118                                                                        │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/train.py:112 in main               │
│                                                                              │
│   109 │   runner = get_runner_class(cfg)(                                    │
│   110 │   │   cfg=cfg, job_id=job_id, task=task, model=model, datasets=datas │
│   111 │   )                                                                  │
│ ❱ 112 │   runner.train()                                                     │
│   113                                                                        │
│   114                                                                        │
│   115 if __name__ == "__main__":                                             │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/runners/runner_base.py:380   │
│ in train                                                                     │
│                                                                              │
│   377 │   │   │   │   for split_name in self.valid_splits:                   │
│   378 │   │   │   │   │   logging.info("Evaluating on {}.".format(split_name │
│   379 │   │   │   │   │                                                      │
│ ❱ 380 │   │   │   │   │   val_log = self.eval_epoch(                         │
│   381 │   │   │   │   │   │   split_name=split_name, cur_epoch=cur_epoch     │
│   382 │   │   │   │   │   )                                                  │
│   383 │   │   │   │   │   if val_log is not None:                            │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/ │
│ autograd/grad_mode.py:28 in decorate_context                                 │
│                                                                              │
│    25 │   │   @functools.wraps(func)                                         │
│    26 │   │   def decorate_context(*args, **kwargs):                         │
│    27 │   │   │   with self.__class__():                                     │
│ ❱  28 │   │   │   │   return func(*args, **kwargs)                           │
│    29 │   │   return cast(F, decorate_context)                               │
│    30 │                                                                      │
│    31 │   def _wrap_generator(self, func):                                   │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/runners/runner_base.py:472   │
│ in eval_epoch                                                                │
│                                                                              │
│   469 │   │   results = self.task.evaluation(model, data_loader)             │
│   470 │   │                                                                  │
│   471 │   │   if results is not None:                                        │
│ ❱ 472 │   │   │   return self.task.after_evaluation(                         │
│   473 │   │   │   │   val_result=results,                                    │
│   474 │   │   │   │   split_name=split_name,                                 │
│   475 │   │   │   │   epoch=cur_epoch,                                       │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/tasks/captioning.py:74 in    │
│ after_evaluation                                                             │
│                                                                              │
│    71 │   │   )                                                              │
│    72 │   │                                                                  │
│    73 │   │   if self.report_metric:                                         │
│ ❱  74 │   │   │   metrics = self._report_metrics(                            │
│    75 │   │   │   │   eval_result_file=eval_result_file, split_name=split_na │
│    76 │   │   │   )                                                          │
│    77 │   │   else:                                                          │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/common/dist_utils.py:112 in  │
│ wrapper                                                                      │
│                                                                              │
│   109 │   def wrapper(*args, **kwargs):                                      │
│   110 │   │   rank, _ = get_dist_info()                                      │
│   111 │   │   if rank == 0:                                                  │
│ ❱ 112 │   │   │   return func(*args, **kwargs)                               │
│   113 │                                                                      │
│   114 │   return wrapper                                                     │
│   115                                                                        │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/tasks/captioning.py:87 in    │
│ _report_metrics                                                              │
│                                                                              │
│    84 │   │                                                                  │
│    85 │   │   # TODO better way to define this                               │
│    86 │   │   coco_gt_root = os.path.join(registry.get_path("cache_root"), " │
│ ❱  87 │   │   coco_val = coco_caption_eval(coco_gt_root, eval_result_file, s │
│    88 │   │                                                                  │
│    89 │   │   agg_metrics = coco_val.eval["CIDEr"] + coco_val.eval["Bleu_4"] │
│    90 │   │   log_stats = {split_name: {k: v for k, v in coco_val.eval.items │
│                                                                              │
│ /public/home/mswanghao/TorchProject/lavis/lavis/tasks/captioning.py:119 in   │
│ coco_caption_eval                                                            │
│                                                                              │
│   116 │   │   "test": "coco_karpathy_test_gt.json",                          │
│   117 │   }                                                                  │
│   118 │                                                                      │
│ ❱ 119 │   download_url(urls[split], coco_gt_root)                            │
│   120 │   annotation_file = os.path.join(coco_gt_root, filenames[split])     │
│   121 │                                                                      │
│   122 │   # create coco object and coco_result object                        │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torchv │
│ ision/datasets/utils.py:129 in download_url                                  │
│                                                                              │
│   126 │   │   _download_file_from_remote_location(fpath, url)                │
│   127 │   else:                                                              │
│   128 │   │   # expand redirect chain if needed                              │
│ ❱ 129 │   │   url = _get_redirect_url(url, max_hops=max_redirect_hops)       │
│   130 │   │                                                                  │
│   131 │   │   # check if file is located on Google Drive                     │
│   132 │   │   file_id = _get_google_drive_file_id(url)                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torchv │
│ ision/datasets/utils.py:77 in _get_redirect_url                              │
│                                                                              │
│    74 │   headers = {"Method": "HEAD", "User-Agent": USER_AGENT}             │
│    75 │                                                                      │
│    76 │   for _ in range(max_hops + 1):                                      │
│ ❱  77 │   │   with urllib.request.urlopen(urllib.request.Request(url, header │
│    78 │   │   │   if response.url == url or response.url is None:            │
│    79 │   │   │   │   return url                                             │
│    80                                                                        │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:21 │
│ 4 in urlopen                                                                 │
│                                                                              │
│    211 │   │   _opener = opener = build_opener()                             │
│    212 │   else:                                                             │
│    213 │   │   opener = _opener                                              │
│ ❱  214 │   return opener.open(url, data, timeout)                            │
│    215                                                                       │
│    216 def install_opener(opener):                                           │
│    217 │   global _opener                                                    │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:51 │
│ 7 in open                                                                    │
│                                                                              │
│    514 │   │   │   req = meth(req)                                           │
│    515 │   │                                                                 │
│    516 │   │   sys.audit('urllib.Request', req.full_url, req.data, req.heade │
│ ❱  517 │   │   response = self._open(req, data)                              │
│    518 │   │                                                                 │
│    519 │   │   # post-process response                                       │
│    520 │   │   meth_name = protocol+"_response"                              │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:53 │
│ 4 in _open                                                                   │
│                                                                              │
│    531 │   │   │   return result                                             │
│    532 │   │                                                                 │
│    533 │   │   protocol = req.type                                           │
│ ❱  534 │   │   result = self._call_chain(self.handle_open, protocol, protoco │
│    535 │   │   │   │   │   │   │   │     '_open', req)                       │
│    536 │   │   if result:                                                    │
│    537 │   │   │   return result                                             │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:49 │
│ 4 in _call_chain                                                             │
│                                                                              │
│    491 │   │   handlers = chain.get(kind, ())                                │
│    492 │   │   for handler in handlers:                                      │
│    493 │   │   │   func = getattr(handler, meth_name)                        │
│ ❱  494 │   │   │   result = func(*args)                                      │
│    495 │   │   │   if result is not None:                                    │
│    496 │   │   │   │   return result                                         │
│    497                                                                       │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:13 │
│ 89 in https_open                                                             │
│                                                                              │
│   1386 │   │   │   self._check_hostname = check_hostname                     │
│   1387 │   │                                                                 │
│   1388 │   │   def https_open(self, req):                                    │
│ ❱ 1389 │   │   │   return self.do_open(http.client.HTTPSConnection, req,     │
│   1390 │   │   │   │   context=self._context, check_hostname=self._check_hos │
│   1391 │   │                                                                 │
│   1392 │   │   https_request = AbstractHTTPHandler.do_request_               │
│                                                                              │
│ /public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/urllib/request.py:13 │
│ 49 in do_open                                                                │
│                                                                              │
│   1346 │   │   │   │   h.request(req.get_method(), req.selector, req.data, h │
│   1347 │   │   │   │   │   │     encode_chunked=req.has_header('Transfer-enc │
│   1348 │   │   │   except OSError as err: # timeout error                    │
│ ❱ 1349 │   │   │   │   raise URLError(err)                                   │
│   1350 │   │   │   r = h.getresponse()                                       │
│   1351 │   │   except:                                                       │
│   1352 │   │   │   h.close()                                                 │
╰──────────────────────────────────────────────────────────────────────────────╯
URLError: <urlopen error [Errno -2] Name or service not known>
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 9249 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 9250 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 9251 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 9248) of binary: /public/home/mswanghao/anaconda3/envs/LLM/bin/python
Traceback (most recent call last):
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 723, in <module>
    main()
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 719, in main
    run(args)
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 710, in run
    elastic_launch(
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/public/home/mswanghao/anaconda3/envs/LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-18_18:54:29
  host      : b06r2n19
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 9248)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
