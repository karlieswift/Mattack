WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
loss DRSL3 b=1e-05 start=0 end=100
loss DRSL3 b=1e-05 start=0 end=100
loss DRSL3 b=1e-05 start=0 end=100
loss DRSL3 b=1e-05 start=0 end=100
| distributed init (rank 3, world 4): env://
| distributed init (rank 1, world 4): env://| distributed init (rank 2, world 4): env://| distributed init (rank 0, world 4): env://


[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
[W Module.cpp:513] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())
2023-08-18 23:50:18,081 [INFO] 
=====  Running Parameters    =====
2023-08-18 23:50:18,091 [INFO] {
    "amp": true,
    "batch_size_eval": 2,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 0.0005,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 10,
    "min_lr": 1e-05,
    "num_workers": 4,
    "output_dir": "output2/BLIP2/DRSL3_0_100_Pretrain_stage2",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "image_text_pretrain",
    "train_splits": [
        "train"
    ],
    "warmup_lr": 1e-06,
    "warmup_steps": 2000,
    "weight_decay": 0.05,
    "world_size": 4
}
2023-08-18 23:50:18,091 [INFO] 
======  Dataset Attributes  ======
2023-08-18 23:50:18,092 [INFO] 
======== coco_caption =======
2023-08-18 23:50:18,093 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip2_image_train"
        }
    }
}
2023-08-18 23:50:18,093 [INFO] 
======  Model Attributes  ======
2023-08-18 23:50:18,093 [INFO] {
    "arch": "blip2_opt",
    "drop_path_rate": 0,
    "finetuned": "",
    "freeze_vit": true,
    "image_size": 224,
    "load_finetuned": false,
    "load_pretrained": true,
    "model_type": "pretrain_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth",
    "prompt": "",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /public/home/mswanghao/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-08-18 23:50:18,097 [INFO] Building datasets...
2023-08-18 23:50:48,853 [INFO] freeze vision encoder
2023-08-18 23:52:50,429 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth
2023-08-18 23:52:50,475 [INFO] Start training
2023-08-18 23:53:06,435 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-08-18 23:53:06,437 [INFO] Loaded 566747 records for train split from the dataset.
2023-08-18 23:53:06,437 [INFO] Loaded 5000 records for val split from the dataset.
2023-08-18 23:53:06,437 [INFO] Loaded 5000 records for test split from the dataset.
2023-08-18 23:53:06,481 [INFO] number of trainable parameters: 107133696
2023-08-18 23:53:06,483 [INFO] Start training epoch 0, 8855 iters per inner epoch.
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
MIOpen(HIP): Warning [ForwardBackwardDataGetWorkSpaceSizeWinograd] /MIOpen/src/sqlite_db.cpp:108: open memvfs: unable to open database file
Train: data epoch: [0]  [   0/8855]  eta: 2 days, 11:16:09  lr: 0.000001  loss: 6.2856  time: 24.0959  data: 0.0000  max mem: 11494
2023-08-18 23:53:30,618 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [  50/8855]  eta: 10:49:23  lr: 0.000013  loss: 4.3180  time: 3.9937  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 100/8855]  eta: 10:13:44  lr: 0.000026  loss: 3.8472  time: 4.0213  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 150/8855]  eta: 9:59:40  lr: 0.000038  loss: 3.4462  time: 3.9506  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 200/8855]  eta: 9:50:40  lr: 0.000051  loss: 2.7319  time: 3.9820  data: 0.0000  max mem: 13574
Train: data epoch: [0]  [ 250/8855]  eta: 9:44:29  lr: 0.000063  loss: 3.3446  time: 4.0000  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 300/8855]  eta: 9:39:12  lr: 0.000076  loss: 2.6140  time: 4.0270  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 350/8855]  eta: 9:33:37  lr: 0.000088  loss: 2.5755  time: 3.9487  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 400/8855]  eta: 9:29:18  lr: 0.000101  loss: 2.4062  time: 4.0122  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 450/8855]  eta: 9:25:42  lr: 0.000113  loss: 2.2664  time: 4.0147  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 500/8855]  eta: 9:21:06  lr: 0.000126  loss: 2.4792  time: 3.9484  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 550/8855]  eta: 9:17:00  lr: 0.000138  loss: 2.4058  time: 3.9633  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 600/8855]  eta: 9:13:25  lr: 0.000151  loss: 2.4240  time: 3.9989  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 650/8855]  eta: 9:10:01  lr: 0.000163  loss: 2.2729  time: 4.0068  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 700/8855]  eta: 9:06:13  lr: 0.000176  loss: 2.5639  time: 3.9549  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 750/8855]  eta: 9:02:13  lr: 0.000188  loss: 2.3482  time: 3.9573  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 800/8855]  eta: 8:58:52  lr: 0.000201  loss: 2.1111  time: 3.9696  data: 0.0000  max mem: 13577
Train: data epoch: [0]  [ 850/8855]  eta: 8:55:25  lr: 0.000213  loss: 2.5854  time: 3.9988  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [ 900/8855]  eta: 8:52:13  lr: 0.000226  loss: 3.6425  time: 4.0564  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [ 950/8855]  eta: 8:48:47  lr: 0.000238  loss: 2.8273  time: 3.9928  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1000/8855]  eta: 8:45:24  lr: 0.000251  loss: 2.7582  time: 3.9988  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1050/8855]  eta: 8:41:58  lr: 0.000263  loss: 2.9730  time: 4.0076  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1100/8855]  eta: 8:38:41  lr: 0.000275  loss: 3.2688  time: 4.0031  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1150/8855]  eta: 8:35:11  lr: 0.000288  loss: 2.6137  time: 3.9675  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1200/8855]  eta: 8:31:48  lr: 0.000300  loss: 3.0646  time: 4.0360  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1250/8855]  eta: 8:28:26  lr: 0.000313  loss: 2.5551  time: 4.0010  data: 0.0000  max mem: 13598
Train: data epoch: [0]  [1300/8855]  eta: 8:25:01  lr: 0.000325  loss: 2.8773  time: 4.0017  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1350/8855]  eta: 8:21:27  lr: 0.000338  loss: 2.8032  time: 3.9600  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1400/8855]  eta: 8:18:04  lr: 0.000350  loss: 2.3846  time: 4.0379  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1450/8855]  eta: 8:14:34  lr: 0.000363  loss: 2.5301  time: 3.9493  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1500/8855]  eta: 8:11:07  lr: 0.000375  loss: 2.4636  time: 4.0032  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1550/8855]  eta: 8:07:35  lr: 0.000388  loss: 2.3736  time: 3.9852  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1600/8855]  eta: 8:04:04  lr: 0.000400  loss: 2.8280  time: 3.9252  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1650/8855]  eta: 8:00:42  lr: 0.000413  loss: 2.3404  time: 4.0191  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1700/8855]  eta: 7:57:17  lr: 0.000425  loss: 2.1921  time: 3.9958  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1750/8855]  eta: 7:53:50  lr: 0.000438  loss: 2.3921  time: 3.9122  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1800/8855]  eta: 7:50:29  lr: 0.000450  loss: 2.3029  time: 3.9468  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1850/8855]  eta: 7:47:04  lr: 0.000463  loss: 2.4738  time: 3.9311  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1900/8855]  eta: 7:43:42  lr: 0.000475  loss: 2.5000  time: 4.0255  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [1950/8855]  eta: 7:40:21  lr: 0.000488  loss: 2.3451  time: 3.9705  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2000/8855]  eta: 7:36:59  lr: 0.000500  loss: 2.4527  time: 4.0282  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2050/8855]  eta: 7:33:38  lr: 0.000500  loss: 2.5921  time: 3.9587  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2100/8855]  eta: 7:30:20  lr: 0.000500  loss: 2.3855  time: 4.0241  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2150/8855]  eta: 7:26:52  lr: 0.000500  loss: 2.3547  time: 3.9702  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2200/8855]  eta: 7:23:28  lr: 0.000500  loss: 2.1654  time: 3.9766  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2250/8855]  eta: 7:20:02  lr: 0.000500  loss: 2.0609  time: 3.9279  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2300/8855]  eta: 7:16:39  lr: 0.000500  loss: 2.4456  time: 3.9768  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2350/8855]  eta: 7:13:20  lr: 0.000500  loss: 2.1969  time: 4.0251  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2400/8855]  eta: 7:10:07  lr: 0.000500  loss: 2.5086  time: 4.0850  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2450/8855]  eta: 7:06:49  lr: 0.000500  loss: 2.2484  time: 3.9750  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2500/8855]  eta: 7:03:28  lr: 0.000500  loss: 2.2137  time: 4.0184  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2550/8855]  eta: 7:00:12  lr: 0.000500  loss: 2.5029  time: 4.0540  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2600/8855]  eta: 6:56:54  lr: 0.000500  loss: 1.9189  time: 3.9416  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2650/8855]  eta: 6:53:36  lr: 0.000500  loss: 2.4875  time: 3.9882  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2700/8855]  eta: 6:50:16  lr: 0.000500  loss: 2.3946  time: 4.0301  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2750/8855]  eta: 6:46:55  lr: 0.000500  loss: 2.1751  time: 3.9667  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2800/8855]  eta: 6:43:32  lr: 0.000500  loss: 2.4253  time: 3.9591  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2850/8855]  eta: 6:40:10  lr: 0.000500  loss: 2.1224  time: 3.9719  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2900/8855]  eta: 6:36:48  lr: 0.000500  loss: 2.4019  time: 3.9838  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [2950/8855]  eta: 6:33:28  lr: 0.000500  loss: 1.9918  time: 4.0118  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3000/8855]  eta: 6:30:07  lr: 0.000500  loss: 2.4716  time: 3.9750  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3050/8855]  eta: 6:26:49  lr: 0.000500  loss: 2.5935  time: 4.0143  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3100/8855]  eta: 6:23:28  lr: 0.000500  loss: 2.4421  time: 3.9932  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3150/8855]  eta: 6:20:07  lr: 0.000500  loss: 2.2112  time: 3.9986  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3200/8855]  eta: 6:16:44  lr: 0.000500  loss: 2.2580  time: 4.0066  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3250/8855]  eta: 6:13:25  lr: 0.000500  loss: 2.0011  time: 4.0032  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3300/8855]  eta: 6:10:04  lr: 0.000500  loss: 2.4812  time: 3.9975  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3350/8855]  eta: 6:06:42  lr: 0.000500  loss: 2.1672  time: 3.9254  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3400/8855]  eta: 6:03:21  lr: 0.000500  loss: 1.9967  time: 3.9719  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3450/8855]  eta: 6:00:06  lr: 0.000500  loss: 2.3973  time: 4.0184  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3500/8855]  eta: 5:56:45  lr: 0.000500  loss: 2.2894  time: 3.9359  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3550/8855]  eta: 5:53:27  lr: 0.000500  loss: 2.2593  time: 4.0286  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3600/8855]  eta: 5:50:06  lr: 0.000500  loss: 2.4312  time: 3.9848  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3650/8855]  eta: 5:46:46  lr: 0.000500  loss: 2.4192  time: 4.0095  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3700/8855]  eta: 5:43:26  lr: 0.000500  loss: 2.4405  time: 4.0002  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3750/8855]  eta: 5:40:07  lr: 0.000500  loss: 2.3900  time: 3.9662  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3800/8855]  eta: 5:36:48  lr: 0.000500  loss: 2.4217  time: 4.0107  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3850/8855]  eta: 5:33:27  lr: 0.000500  loss: 2.3960  time: 3.9672  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3900/8855]  eta: 5:30:07  lr: 0.000500  loss: 2.0223  time: 3.9637  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [3950/8855]  eta: 5:26:47  lr: 0.000500  loss: 2.1295  time: 3.9971  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4000/8855]  eta: 5:23:28  lr: 0.000500  loss: 2.3398  time: 4.0102  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4050/8855]  eta: 5:20:06  lr: 0.000500  loss: 2.5097  time: 3.9608  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4100/8855]  eta: 5:16:50  lr: 0.000500  loss: 2.6037  time: 4.0808  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4150/8855]  eta: 5:13:32  lr: 0.000500  loss: 2.2295  time: 4.0354  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4200/8855]  eta: 5:10:12  lr: 0.000500  loss: 2.0677  time: 4.0115  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4250/8855]  eta: 5:06:52  lr: 0.000500  loss: 2.3053  time: 4.0406  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4300/8855]  eta: 5:03:32  lr: 0.000500  loss: 2.1411  time: 4.0047  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4350/8855]  eta: 5:00:13  lr: 0.000500  loss: 2.2164  time: 3.9995  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4400/8855]  eta: 4:56:52  lr: 0.000500  loss: 2.3204  time: 3.9731  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4450/8855]  eta: 4:53:35  lr: 0.000500  loss: 2.0479  time: 4.0293  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4500/8855]  eta: 4:50:15  lr: 0.000500  loss: 2.7442  time: 3.9785  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4550/8855]  eta: 4:46:55  lr: 0.000500  loss: 2.3541  time: 3.9864  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4600/8855]  eta: 4:43:35  lr: 0.000500  loss: 2.3946  time: 4.0078  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4650/8855]  eta: 4:40:14  lr: 0.000500  loss: 2.1648  time: 4.0035  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4700/8855]  eta: 4:36:55  lr: 0.000500  loss: 2.1327  time: 4.0127  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4750/8855]  eta: 4:33:37  lr: 0.000500  loss: 2.6390  time: 4.0111  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4800/8855]  eta: 4:30:17  lr: 0.000500  loss: 2.3182  time: 3.9954  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4850/8855]  eta: 4:26:56  lr: 0.000500  loss: 2.0344  time: 3.9885  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4900/8855]  eta: 4:23:35  lr: 0.000500  loss: 2.4574  time: 3.9571  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [4950/8855]  eta: 4:20:16  lr: 0.000500  loss: 2.0873  time: 4.0020  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5000/8855]  eta: 4:16:54  lr: 0.000500  loss: 1.9910  time: 3.9461  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5050/8855]  eta: 4:13:34  lr: 0.000500  loss: 2.5029  time: 3.9864  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5100/8855]  eta: 4:10:15  lr: 0.000500  loss: 2.0977  time: 3.9984  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5150/8855]  eta: 4:06:56  lr: 0.000500  loss: 2.4432  time: 4.0193  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5200/8855]  eta: 4:03:35  lr: 0.000500  loss: 2.2649  time: 3.9869  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5250/8855]  eta: 4:00:16  lr: 0.000500  loss: 2.1722  time: 3.9385  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5300/8855]  eta: 3:56:57  lr: 0.000500  loss: 2.1797  time: 4.0479  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5350/8855]  eta: 3:53:37  lr: 0.000500  loss: 2.0960  time: 4.0327  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5400/8855]  eta: 3:50:18  lr: 0.000500  loss: 2.0377  time: 3.9956  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5450/8855]  eta: 3:46:57  lr: 0.000500  loss: 2.2059  time: 3.9545  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5500/8855]  eta: 3:43:37  lr: 0.000500  loss: 2.1717  time: 3.9523  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5550/8855]  eta: 3:40:17  lr: 0.000500  loss: 2.0635  time: 4.0182  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5600/8855]  eta: 3:36:57  lr: 0.000500  loss: 2.0609  time: 3.9774  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5650/8855]  eta: 3:33:37  lr: 0.000500  loss: 2.1826  time: 4.0186  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5700/8855]  eta: 3:30:16  lr: 0.000500  loss: 2.3878  time: 3.9395  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5750/8855]  eta: 3:26:56  lr: 0.000500  loss: 2.2801  time: 4.0393  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5800/8855]  eta: 3:23:37  lr: 0.000500  loss: 1.9044  time: 4.0139  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5850/8855]  eta: 3:20:17  lr: 0.000500  loss: 2.3451  time: 4.0136  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5900/8855]  eta: 3:16:58  lr: 0.000500  loss: 1.8096  time: 4.0457  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [5950/8855]  eta: 3:13:38  lr: 0.000500  loss: 2.6986  time: 4.0189  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6000/8855]  eta: 3:10:18  lr: 0.000500  loss: 2.1391  time: 4.0101  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6050/8855]  eta: 3:06:59  lr: 0.000500  loss: 2.4646  time: 4.0519  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6100/8855]  eta: 3:03:40  lr: 0.000500  loss: 2.2037  time: 4.0481  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6150/8855]  eta: 3:00:20  lr: 0.000500  loss: 2.4077  time: 4.0223  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6200/8855]  eta: 2:57:00  lr: 0.000500  loss: 2.4440  time: 3.9869  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6250/8855]  eta: 2:53:40  lr: 0.000500  loss: 2.2597  time: 4.0115  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6300/8855]  eta: 2:50:21  lr: 0.000500  loss: 2.1132  time: 4.0143  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6350/8855]  eta: 2:47:01  lr: 0.000500  loss: 2.2522  time: 4.0294  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6400/8855]  eta: 2:43:42  lr: 0.000500  loss: 2.3858  time: 4.0745  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6450/8855]  eta: 2:40:23  lr: 0.000500  loss: 2.4245  time: 4.0006  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6500/8855]  eta: 2:37:03  lr: 0.000500  loss: 2.2799  time: 4.0293  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6550/8855]  eta: 2:33:43  lr: 0.000500  loss: 2.6931  time: 4.0387  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6600/8855]  eta: 2:30:24  lr: 0.000500  loss: 2.2034  time: 4.0440  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6650/8855]  eta: 2:27:04  lr: 0.000500  loss: 2.2604  time: 4.0157  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6700/8855]  eta: 2:23:44  lr: 0.000500  loss: 2.1305  time: 4.0184  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6750/8855]  eta: 2:20:25  lr: 0.000500  loss: 2.5726  time: 4.0790  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6800/8855]  eta: 2:17:05  lr: 0.000500  loss: 2.1573  time: 4.0312  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6850/8855]  eta: 2:13:45  lr: 0.000500  loss: 1.9221  time: 4.0331  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6900/8855]  eta: 2:10:25  lr: 0.000500  loss: 2.0151  time: 4.0082  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [6950/8855]  eta: 2:07:06  lr: 0.000500  loss: 2.3401  time: 4.0438  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7000/8855]  eta: 2:03:46  lr: 0.000500  loss: 2.0983  time: 3.9918  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7050/8855]  eta: 2:00:26  lr: 0.000500  loss: 2.2049  time: 4.0479  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7100/8855]  eta: 1:57:06  lr: 0.000500  loss: 2.1154  time: 4.0055  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7150/8855]  eta: 1:53:46  lr: 0.000500  loss: 2.5335  time: 4.0001  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7200/8855]  eta: 1:50:26  lr: 0.000500  loss: 2.0483  time: 4.0198  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7250/8855]  eta: 1:47:06  lr: 0.000500  loss: 2.2089  time: 4.0122  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7300/8855]  eta: 1:43:46  lr: 0.000500  loss: 2.3369  time: 4.0313  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7350/8855]  eta: 1:40:27  lr: 0.000500  loss: 2.4871  time: 4.0336  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7400/8855]  eta: 1:37:07  lr: 0.000500  loss: 2.4407  time: 4.0009  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7450/8855]  eta: 1:33:47  lr: 0.000500  loss: 2.3583  time: 4.0230  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7500/8855]  eta: 1:30:27  lr: 0.000500  loss: 2.5901  time: 4.0243  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7550/8855]  eta: 1:27:07  lr: 0.000500  loss: 2.5026  time: 4.0349  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7600/8855]  eta: 1:23:47  lr: 0.000500  loss: 2.5921  time: 4.0185  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7650/8855]  eta: 1:20:26  lr: 0.000500  loss: 2.3441  time: 4.0226  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7700/8855]  eta: 1:17:06  lr: 0.000500  loss: 2.3512  time: 3.9695  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7750/8855]  eta: 1:13:46  lr: 0.000500  loss: 2.0077  time: 4.0113  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7800/8855]  eta: 1:10:25  lr: 0.000500  loss: 2.2355  time: 3.9660  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7850/8855]  eta: 1:07:05  lr: 0.000500  loss: 2.1601  time: 4.0208  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7900/8855]  eta: 1:03:45  lr: 0.000500  loss: 2.0644  time: 4.0183  data: 0.0000  max mem: 13606
Train: data epoch: [0]  [7950/8855]  eta: 1:00:25  lr: 0.000500  loss: 2.4312  time: 4.0339  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8000/8855]  eta: 0:57:05  lr: 0.000500  loss: 2.2586  time: 4.0118  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8050/8855]  eta: 0:53:44  lr: 0.000500  loss: 2.5542  time: 4.0198  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8100/8855]  eta: 0:50:24  lr: 0.000500  loss: 2.3325  time: 3.9829  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8150/8855]  eta: 0:47:04  lr: 0.000500  loss: 1.9823  time: 4.0400  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8200/8855]  eta: 0:43:44  lr: 0.000500  loss: 2.1939  time: 4.0554  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8250/8855]  eta: 0:40:24  lr: 0.000500  loss: 2.0627  time: 3.9796  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8300/8855]  eta: 0:37:03  lr: 0.000500  loss: 2.1378  time: 4.0039  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8350/8855]  eta: 0:33:43  lr: 0.000500  loss: 2.4525  time: 4.0074  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8400/8855]  eta: 0:30:23  lr: 0.000500  loss: 2.0593  time: 4.0587  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8450/8855]  eta: 0:27:02  lr: 0.000500  loss: 1.9966  time: 4.0028  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8500/8855]  eta: 0:23:42  lr: 0.000500  loss: 2.4032  time: 4.0759  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8550/8855]  eta: 0:20:22  lr: 0.000500  loss: 2.3912  time: 4.0313  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8600/8855]  eta: 0:17:01  lr: 0.000500  loss: 2.0153  time: 4.0167  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8650/8855]  eta: 0:13:41  lr: 0.000500  loss: 2.2620  time: 4.0922  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8700/8855]  eta: 0:10:21  lr: 0.000500  loss: 2.3624  time: 3.9965  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8750/8855]  eta: 0:07:00  lr: 0.000500  loss: 2.2547  time: 4.0299  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8800/8855]  eta: 0:03:40  lr: 0.000500  loss: 2.0923  time: 4.0034  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8850/8855]  eta: 0:00:20  lr: 0.000500  loss: 2.0228  time: 3.9649  data: 0.0000  max mem: 13620
Train: data epoch: [0]  [8854/8855]  eta: 0:00:04  lr: 0.000500  loss: 2.1056  time: 3.9853  data: 0.0000  max mem: 13620
Train: data epoch: [0] Total time: 9:51:25 (4.0074 s / it)
2023-08-19 09:44:32,396 [INFO] Averaged stats: lr: 0.0004  loss: 2.3748
2023-08-19 09:44:32,447 [INFO] No validation splits found.
2023-08-19 09:44:32,490 [INFO] Saving checkpoint at epoch 0 to /public/home/mswanghao/TorchProject/lavis/lavis/output2/BLIP2/DRSL3_0_100_Pretrain_stage2/20230818235/checkpoint_0.pth.
2023-08-19 09:44:36,819 [INFO] Start training
2023-08-19 09:44:36,884 [INFO] Start training epoch 1, 8855 iters per inner epoch.
Train: data epoch: [1]  [   0/8855]  eta: 20:04:14  lr: 0.000488  loss: 2.0900  time: 8.1598  data: 0.0000  max mem: 13620
Train: data epoch: [1]  [  50/8855]  eta: 10:03:45  lr: 0.000488  loss: 2.0725  time: 4.0388  data: 0.0000  max mem: 13620
Train: data epoch: [1]  [ 100/8855]  eta: 9:55:09  lr: 0.000488  loss: 2.3154  time: 4.0443  data: 0.0000  max mem: 13620
Train: data epoch: [1]  [ 150/8855]  eta: 9:50:10  lr: 0.000488  loss: 2.4078  time: 4.0128  data: 0.0000  max mem: 13620
slurmstepd: error: *** JOB 13004238 ON a12r1n04 CANCELLED AT 2023-08-19T09:56:21 ***
